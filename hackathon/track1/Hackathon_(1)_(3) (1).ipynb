{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwimwznZCrJJ"
      },
      "source": [
        "**Setup Ollama**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01Cy3JcVCqBZ",
        "outputId": "59faa644-afaf-4d49-f7e3-7c3c64538cb2"
      },
      "outputs": [],
      "source": [
        "# !pip install -q mcp-server sentence-transformers  PyMuPDF\n",
        "# !pip install -q gradio\n",
        "# !pip install -q langchain-community\n",
        "# !pip install -U --quiet langgraph\n",
        "# !pip install -q python-docx\n",
        "# !pip install -q chromadb\n",
        "# !pip install -q faiss-cpu\n",
        "# !pip install -U langchain-deepseek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgvqvsEVH4_W",
        "outputId": "2d70e1bc-9dd4-467c-b3e2-58f0f5ad3144"
      },
      "outputs": [],
      "source": [
        "# !pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rh5sucWBDMhU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\envs\\mcp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import json\n",
        "import queue\n",
        "import threading\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Any\n",
        "\n",
        "import gradio as gr\n",
        "import pdfplumber\n",
        "import docx\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import requests\n",
        "\n",
        "import os, hashlib, tempfile, pathlib, torch, re, traceback\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langgraph.graph import MessagesState, StateGraph\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import pdfplumber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_LhyC_KczlH"
      },
      "source": [
        "**Global Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YM9-KifvO6_Q"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# #api deepseek r1\n",
        "# os.environ[\"NEBIUS_API_KEY\"] = \"eyJhbGciOiJIUzI1NiIsImtpZCI6IlV6SXJWd1h0dnprLVRvdzlLZWstc0M1akptWXBvX1VaVkxUZlpnMDRlOFUiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJnb29nbGUtb2F1dGgyfDExMTYxMjA0MzQ0ODU0NTI5MTczNCIsInNjb3BlIjoib3BlbmlkIG9mZmxpbmVfYWNjZXNzIiwiaXNzIjoiYXBpX2tleV9pc3N1ZXIiLCJhdWQiOlsiaHR0cHM6Ly9uZWJpdXMtaW5mZXJlbmNlLmV1LmF1dGgwLmNvbS9hcGkvdjIvIl0sImV4cCI6MTkwNzA0Mjc0OCwidXVpZCI6ImY4ZWEzOGUyLTllNjktNDM3NS05YjkzLWE3Y2EzMThiMjZjZCIsIm5hbWUiOiJoYWNrYXRob24iLCJleHBpcmVzX2F0IjoiMjAzMC0wNi0wN1QwNjowNTo0OCswMDAwIn0.DH7JrezDuqrl2SPMdWdWWnWgBPrvBbe9yucG29-3YpQ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from openai import OpenAI\n",
        "# client = OpenAI(\n",
        "#     base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "#     api_key=os.getenv(\"NEBIUS_API_KEY\")\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560,
          "referenced_widgets": [
            "b5d5316bca1b47ffbfbbf4b81f97677d",
            "982650b100534a24828cd2b6c2f22930",
            "57486e1bee634103aa480427f0b6ec08",
            "a2659e102400400586d017104043047f",
            "f26bf85d31024f9ba8a24b4b0061dabf",
            "f29b7bccb7d645c5968bfce8eb1f5652",
            "c24968ac006847cabcd295f518dc9482",
            "40aae9a337f145538a8c5ac1b97d3312",
            "0f6e4273dcfc40f8b24fd84bee1a715c",
            "4ed4b4d8ce244f6ca4e03b86920983b6",
            "80d1beac3e2d435081981c8bf599e3bc",
            "5df6bcfae5a34f57b1e0652632ec7975",
            "38d8f33510ef47d894eebcbeee08d437",
            "faf5e9d426fd468cb7ff98ebc1150e05",
            "874c09f5a4b14ee197f447ede88c3a01",
            "9aeff405f7e143868972a21fe77df5c1",
            "1e87b5199fbe42ddbf17784edb27e10e",
            "d9dd995cca374fd580e0b8dfd0cc1013",
            "ddb77d6eabd14526888186556c4079cb",
            "49c5def60dc24f97afca4c5f1032c29a",
            "131620843a094e248361d1bc4896b2d0",
            "063e6591e62942e6a891ee4fd0fc4f4a",
            "5c613320f9e742a2b92895c10495b301",
            "3e651b07d24743e7879935a2e1459d5e",
            "bdd5d4554d3b4453b6bfe3baa0d9d855",
            "7d1e3e77c4fd491888855a001d893193",
            "b70cac465c114f999e0107ef94090e02",
            "ec5253662f034283b08189c37082f038",
            "affbf9b569fb4d639db71b59ee110971",
            "d749edb8f8e9424da6dba63f2f549ba5",
            "796dc6e4540a41a882e47e139e998d97",
            "83cd097a36bc4cc38f3a430f5afd513b",
            "22499d3939b545938d65a5909f02766d",
            "68a3274bfd0e40f9b9468b94f774c65e",
            "53a9f2c47b904f89abba682034e5e7d2",
            "942bafa6818f4cb9aba20912b6dc1c3f",
            "7fa73d2ebd3544ad84d405912aa8c59a",
            "89c7431bf9db4e678fccd4cc73cac10e",
            "0d0b61c1203b45569076708adba47b2d",
            "fba5aa0ff3d14cc1b7c750cbe387db7d",
            "f999c2cbd3f848e1992caac791b93f31",
            "46f33e1bc6ad447ea294a1af4a41a9af",
            "ae6918205ee445e7adcfdb57decf87d5",
            "931137748edc44749f4e32fb92009f8f",
            "d7ae7d550e02405e922b18854819c424",
            "a517ea27204f469eab09e90cacc0e757",
            "4337f57e09374dd9b8cbf81ce7fda17d",
            "9ffec56b78d04badabd0e2f02dade714",
            "cfbc4171d3104a71bc5d08cf003ed58f",
            "9a3b1117e200404fbf618b7574cb9774",
            "c2b62d1556b042758f5f319ed0bb1ff0",
            "d2fea39e25d24b02aea5fb4cdb56d4fa",
            "b2c5c2dabab64ed68f6dda058729ba88",
            "2d78949de0c345caaa80aa780e0934f2",
            "d9e3227c1db74df29bf6121b2aeb524f",
            "3129845c57ff420ea08afc18e759ff03",
            "b2d9a486801641128790693f6b811341",
            "897c2c43a4b643fd8089904e2be2be76",
            "a9fa96245b3244ac947f228aa962a53c",
            "7a46fe31b6454df08236a3e007760d28",
            "950cb5b687e24000863dc5aa11e9eafc",
            "a9d64b90eadb4a619fa01aec3ddf02c2",
            "103ded8f22c84a8dbbdbc10d533c324a",
            "9f1d5797dee743149324a86312453313",
            "84e3343126aa489284e2ccfbd6dd0ab4",
            "a072a5af013c4e35a928b520e800ceff",
            "32a3547cacdb4d15804899b8970ad58c",
            "44a89aafd86946bf92db65bcf1b5931e",
            "09d5958ede814008bac85304b9e8c768",
            "a1f41c8e7fbb4aeb8855c52cc478ea99",
            "a2e2321c58d3463bb7c5ffba67f6bf34",
            "f32d457f0f8e45c189684d7ec8bee5da",
            "59250aa1f5d44ce6902c40317510a71f",
            "6f3d226db0ae42dbb1f9f0ebbc8db52e",
            "43a9be75c016488b84c49b680b129b34",
            "b2e90a6b57574e83ac4224d5938b6dc2",
            "dfb5ee6d01bd4d5bac7a56f01ec069f3",
            "fcee393ca8344a0fb25f293dd3d90bb1",
            "cdf572db970e4b98ae01c504f2a94803",
            "6f27d902c38b48cb8248f95adaccf594",
            "32d1e8f4521b49aab78342448efaa338",
            "6bb0b63f3e3b4decbf8b82aec9926be8",
            "a53b9608a5e746d0bc80b35d273536dd",
            "1b96592199b14a0d97eaf492874ca20e",
            "53efb6f2caf74690995eca392a283a63",
            "1b7b079d6a6a4c4f96e6c95ddb5a3ee7",
            "47c337c93dae4075a792069576df99f5",
            "49d94e86656140efa2167a2b40cccd73",
            "4fb6d0e2a71f4a29a248fd6c2227cc08",
            "1ec9a47f99c04a2ca2172f0c47b0c3f0",
            "dadd04eea7ee420b9a6dad87c464c232",
            "88256ec2f1f74fdfa02b230b45b6f2b8",
            "ce22a7a57cc045d6ac05baa7e433fb42",
            "a12e3176d41c4fcda3b13a6cd983a157",
            "e7f6fc7e3f9f48fdbc432d5c86ee0a74",
            "142398f32e3a4bffaf3f65020b09d99f",
            "795adb5e52174b468ba0f4dbe5a32539",
            "522f568c33264fb2a825c5b5a0440681",
            "2417110ee2124366ac8708fda2a7b904",
            "1c70b30501134312a980cd35d90dd674",
            "1310648fb9f240d2a5ebd71e3e4ac352",
            "6f16995cfe9044b1ba7f87623aaeb784",
            "c78b49ebe9a3421086983c6172e0913d",
            "497c9728938b4aa5a01d8eac5457b191",
            "ef5f0ecb42ab4558830a7fb11b70b1a5",
            "d22ab5f995b6467f93caa6f419a96167",
            "69e995a99f1f420a9d26e8421fdb1b48",
            "a21917da551a48f389c4f27f756c202b",
            "1693f813de7c48ebac0a8adbcd74fd51",
            "c475c20e06b04a318ed77a042570af95",
            "8d5d0a351b764af69b350f385f9b8a93",
            "fcfdac76aa4b4f81a2919120000ca5fc",
            "70fb894aad404373ba8c093667af2b99",
            "ac12a34d49ef41fd8102111a3ab013b3",
            "e0877c08a87a46c1b088f02189b46e85",
            "559dede944534990aad82cfe109f50ef",
            "699a76c40cf9434ea2dfb2880f73a9a1",
            "dfa39cd16d754a75956e63145b42e5be",
            "1d36e496890c404e92101ac453d12f35",
            "23a83708bb0b4a2086c92a95e6624021",
            "eca04492027e4421808c388311842900",
            "db07f4f9259547a8826d8f6d23a983df",
            "2a2a39ae5323447fa70a18da0175eec0",
            "4a9fa1a2b7d94d95963ae208ce36cc27",
            "286c9d6cdcf4420a8f868d65ea173c40",
            "fb827250c250438a807fda758ba0ee12",
            "5c7502dcacd7412e98d1a5cf263e248e",
            "816f1e68e2314e72a2074176117f3f3e",
            "46188d48a66147b683871b43402c0fe5",
            "73a097cb74254b9cb2330a74d8ec23fe",
            "d41a431d09f8437e9bdc8753178cc089",
            "025851cd236c41129503c1ddacf62c8c"
          ]
        },
        "id": "bBOSXdpnOvDi",
        "outputId": "d987cf79-ffbd-4fab-cb69-1d366e6385d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_28460\\1214639332.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  EMBEDDER = HuggingFaceEmbeddings(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from openai import OpenAI\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EMBEDDER = HuggingFaceEmbeddings(\n",
        "    model_name=\"BAAI/bge-m3\",\n",
        "    encode_kwargs={\"normalize_embeddings\": True, \"device\": device},\n",
        ")\n",
        "\n",
        "# client = OpenAI(\n",
        "#     base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "#     api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        "# )\n",
        "# LLM = init_chat_model(\n",
        "#     model=\"deepseek-ai/DeepSeek-V3\",   # use DeepSeek\n",
        "#     base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "#     api_key=os.getenv(\"OPENAI_API_KEY\"),  # your Nebius API key\n",
        "#     temperature=0.4,\n",
        "# )\n",
        "# client = OpenAI(\n",
        "#     base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "#     api_key=os.environ.get(\"NEBIUS_API_KEY\")\n",
        "# )\n",
        "# LLM = client.chat.completions.create(\n",
        "#     model=\"deepseek-ai/DeepSeek-R1\",\n",
        "#     max_tokens=8192,\n",
        "#     temperature=0.6,\n",
        "#     top_p=0.95,\n",
        "#     messages=[]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "LLM = ChatOpenAI(\n",
        "    openai_api_key=\"eyJhbGciOiJIUzI1NiIsImtpZCI6IlV6SXJWd1h0dnprLVRvdzlLZWstc0M1akptWXBvX1VaVkxUZlpnMDRlOFUiLCJ0eXAiOiJKV1QifQ.eyJzdWIiOiJnb29nbGUtb2F1dGgyfDExMTYxMjA0MzQ0ODU0NTI5MTczNCIsInNjb3BlIjoib3BlbmlkIG9mZmxpbmVfYWNjZXNzIiwiaXNzIjoiYXBpX2tleV9pc3N1ZXIiLCJhdWQiOlsiaHR0cHM6Ly9uZWJpdXMtaW5mZXJlbmNlLmV1LmF1dGgwLmNvbS9hcGkvdjIvIl0sImV4cCI6MTkwNzA0Mjc0OCwidXVpZCI6ImY4ZWEzOGUyLTllNjktNDM3NS05YjkzLWE3Y2EzMThiMjZjZCIsIm5hbWUiOiJoYWNrYXRob24iLCJleHBpcmVzX2F0IjoiMjAzMC0wNi0wN1QwNjowNTo0OCswMDAwIn0.DH7JrezDuqrl2SPMdWdWWnWgBPrvBbe9yucG29-3YpQ\",\n",
        "    openai_api_base=\"https://api.studio.nebius.com/v1\",\n",
        "    model=\"Qwen/Qwen2.5-72B-Instruct\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVDpsO9Gw22I"
      },
      "source": [
        "**Handle file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_vKrEL_Rw2dw"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_file_bytes_and_name(pdf_file):\n",
        "    print(\"DEBUG: pdf_file type:\", type(pdf_file))\n",
        "    print(\"DEBUG: pdf_file dir:\", dir(pdf_file))\n",
        "    print(\"DEBUG: pdf_file repr:\", repr(pdf_file))\n",
        "\n",
        "    # Standard file-like object (e.g. Python's open, script mode)\n",
        "    if hasattr(pdf_file, \"read\"):\n",
        "         return pdf_file.read(), Path(pdf_file.name).name\n",
        "    if isinstance(pdf_file, str):\n",
        "        file_path = Path(pdf_file)\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            return f.read(), file_path.name\n",
        "    raise ValueError(\"Could not extract file bytes from uploaded file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmlQHldCOe9H"
      },
      "source": [
        "**Create Vector Database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ppF2HVV_OiWi"
      },
      "outputs": [],
      "source": [
        "VECTOR_ROOT = pathlib.Path.home() / \".rag_vectors\"\n",
        "VECTOR_ROOT.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "E7FHpjwjRP84"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. PDF-to-vectorstore, clean and tag paragraphs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def load_or_create_chroma(pdf_bytes: bytes, filename: str) -> Chroma:\n",
        "    \"\"\"\n",
        "    Loads persistent Chroma vectorstore for this PDF, or creates it if not found.\n",
        "    Each chunk carries page and paragraph info.\n",
        "    \"\"\"\n",
        "    print(f\"\\n[INFO] Checking vectorstore for file: {filename}\")\n",
        "    h = hashlib.md5(pdf_bytes).hexdigest()\n",
        "    vect_dir = VECTOR_ROOT / h\n",
        "    if (vect_dir / \"chroma.sqlite3\").exists():\n",
        "        print(f\"[INFO] Found existing vectorstore: {vect_dir}\")\n",
        "        return Chroma(persist_directory=str(vect_dir), embedding_function=EMBEDDER)\n",
        "\n",
        "    # Otherwise, embed and persist it\n",
        "    print(f\"[INFO] No vectorstore found, embedding file: {filename}\")\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as tmp:\n",
        "        tmp.write(pdf_bytes)\n",
        "        tmp_path = tmp.name\n",
        "\n",
        "    docs = []\n",
        "    BAD_PHRASES = {\n",
        "        \"Abstracting with credit is permitted\",\n",
        "        \"Permission to make digital or hard copies\",\n",
        "        \"arXiv:\",\n",
        "        \"Â©\",\n",
        "    }\n",
        "\n",
        "    def clean_page(text: str) -> str:\n",
        "        return \"\\n\".join(\n",
        "            line for line in text.splitlines()\n",
        "            if not any(b in line for b in BAD_PHRASES)\n",
        "        )\n",
        "\n",
        "    with pdfplumber.open(tmp_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages, start=1):\n",
        "            text = clean_page(page.extract_text() or \"\")\n",
        "            if not text.strip():\n",
        "                continue\n",
        "            # Split into small chunks for embedding\n",
        "            splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "                chunk_size=1200, chunk_overlap=200\n",
        "            )\n",
        "            para_chunks = splitter.split_text(text)\n",
        "            for para_num, chunk in enumerate(para_chunks, start=1):\n",
        "                docs.append(\n",
        "                    Document(\n",
        "                        page_content=chunk,\n",
        "                        metadata={\"page_number\": page_num, \"paragraph_number\": para_num}\n",
        "                    )\n",
        "                )\n",
        "    print(f\"[INFO] Extracted {len(docs)} chunks from PDF for embedding.\")\n",
        "    vectordb = Chroma.from_documents(\n",
        "        docs, EMBEDDER, persist_directory=str(vect_dir)\n",
        "    )\n",
        "    vectordb.persist()\n",
        "    return vectordb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FPOTU3iU7nw"
      },
      "source": [
        "test chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9azeib0Ui8g",
        "outputId": "92d869e9-dd3b-4155-ef75-cbb50e05f658"
      },
      "outputs": [],
      "source": [
        "# with open(\"LoRA.pdf\", \"rb\") as f:\n",
        "#     pdf_bytes = f.read()\n",
        "#     filename = \"/content/2405.10523v1.pdf\"\n",
        "\n",
        "# vectordb = load_or_create_chroma(pdf_bytes, filename)\n",
        "# print(\"Vectorstore loaded/created:\", vectordb)\n",
        "# print(\"Collection count:\", vectordb._collection.count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IFvnxMrppmK"
      },
      "source": [
        "**Create tool**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fIvKm_F-povl"
      },
      "outputs": [],
      "source": [
        "def build_retriever_tool(vectorstore):\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    from langchain.tools.retriever import create_retriever_tool\n",
        "    retriever_tool = create_retriever_tool(\n",
        "        retriever,\n",
        "        name=\"document_search\",    \n",
        "        description=\"Searches uploaded documents and returns relevant passages.\"\n",
        "    )\n",
        "    return retriever_tool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retriever = vectorstore.as_retriever()    \n",
        "# retriever_tool = create_retriever_tool(\n",
        "#         retriever,\n",
        "#         name=\"document_search\",    \n",
        "#         description=\"Searches uploaded documents and returns relevant passages.\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7chfuKZKcgHx"
      },
      "source": [
        "Testing purpose on tool calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv8DqH_qcUxg",
        "outputId": "9bad660e-931a-48ec-9a0a-49a867f356ff"
      },
      "outputs": [],
      "source": [
        "# # Assuming 'vectordb' from your previous test run is available and holds the Chroma vectorstore\n",
        "\n",
        "# retriever_tool = build_retriever_tool(vectordb)\n",
        "# test_query = \"What is the main topic of this document?\"\n",
        "# retrieved_content = retriever_tool.invoke({\"query\": test_query})\n",
        "\n",
        "# print(\"Retrieved content from the tool:\")\n",
        "# print(retrieved_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOzCff0RuslX",
        "outputId": "8e7b6aab-0c39-449e-f51a-99de0653192c"
      },
      "outputs": [],
      "source": [
        "# !find /root/.rag_vectors/ -name chroma.sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hAU7qkIRjm2"
      },
      "source": [
        "***Generate query***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Suijfyy9Ruuj"
      },
      "outputs": [],
      "source": [
        "#this is where the langraph stores the reasoning and the result\n",
        "# response_model = init_chat_model(\"deepseek-ai/DeepSeek-V3\", temperature=0)\n",
        "# def generate_query_or_respond(state: MessagesState):\n",
        "#     \"\"\"Call the model to generate a response based on the current state. Given\n",
        "#     the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
        "#     \"\"\"\n",
        "    \n",
        "#     #state[\"messages\"] refers to the entire messgae history\n",
        "#     print(f\"[DEBUG] LLM node, messages so far: {state['messages']}\")\n",
        "    \n",
        "#     response = ( \n",
        "#         LLM\n",
        "#         .bind_tools([build_retriever_tool]).invoke(state[\"messages\"])\n",
        "#         )\n",
        "#     # response contains the LLM's reply (could be an answer, could be a tool-call)\n",
        "#     return {\"messages\": [response]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_generate_query_or_respond(retriever_tool):\n",
        "    def generate_query_or_respond(state):\n",
        "        response = (\n",
        "            LLM\n",
        "            .bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
        "        )\n",
        "        return {\"messages\": [response]}\n",
        "    return generate_query_or_respond"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# input = {\"messages\": [{\"role\": \"user\", \"content\": \"hello!\"}]}\n",
        "# generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zLJOzujpcCCX"
      },
      "outputs": [],
      "source": [
        "# #this function run the tools and adss passage and citation to the chat\n",
        "\n",
        "# def run_retriever(state: MessagesState):\n",
        "#     #grab the most recent message\n",
        "#     tool_call = state[\"messages\"][-1]\n",
        "#     query = tool_call.tool_input[\"query\"]\n",
        "#     print(f\"[DEBUG] Retriever node, running query: {query}\")\n",
        "#     passages = state[\"retriever_tool\"].invoke({\"query\": query})\n",
        "#     docs = state[\"retriever\"].get_relevant_documents(query)\n",
        "#     citation_lines = []\n",
        "#     for d in docs:\n",
        "#         page = d.metadata.get(\"page_number\", \"â€“\")\n",
        "#         para = d.metadata.get(\"paragraph_number\", \"â€“\")\n",
        "#         citation_lines.append(f\"(P{page} Â¶{para})\")\n",
        "#     passages_w_cite = passages + \"\\n\\n\" + \" \".join(citation_lines)\n",
        "#     print(f\"[DEBUG] Retrieved {len(docs)} docs, citations: {' '.join(citation_lines)}\")\n",
        "#     print(f\"[DEBUG] Passages:\\n{passages}\\n\")\n",
        "#     state[\"messages\"].append(\n",
        "#         {\"role\": \"tool\", \"name\": \"search_pdf\", \"content\": passages_w_cite}\n",
        "#     )\n",
        "#     return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KCHnOI6OUzHK"
      },
      "outputs": [],
      "source": [
        "# #this function check if the llm call the tool, if yes run_retriever function, if no done!\n",
        "\n",
        "# def should_retrieve(state: MessagesState):\n",
        "#     last = state[\"messages\"][-1]\n",
        "#     print(f\"[DEBUG] Grader node: last message: {last}\")\n",
        "#     return \"needs_retrieval\" if getattr(last, \"tool\", None) else \"final\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9ZVcvTgiFxr"
      },
      "source": [
        "Generate answer after call tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sYqvdBSqiE5Y"
      },
      "outputs": [],
      "source": [
        "GENERATE_PROMPT = (\n",
        "    \"You are an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of retrieved context to answer the question with reference and page number.\"\n",
        "    \"attention to the context, and only use it to answer the question. \"\n",
        "    \"If you don't know the answer, just say that you don't know. \"\n",
        "    \"Question: {question} \\n\"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "def generate_answer(state: MessagesState):\n",
        "    print(f\"[DEBUG] Answer node, messages so far: {state['messages']}\")\n",
        "    question = state[\"messages\"][0].content\n",
        "    print(f\"[DEBUG] Question: {question}\")\n",
        "    context = state[\"messages\"][-1].content\n",
        "    print(f\"[DEBUG] Context: {context}\")\n",
        "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
        "    response = LLM.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
        "    print(f\"[DEBUG] LLM final answer: {response}\")\n",
        "    return {\"messages\": [response]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_core.messages import convert_to_messages\n",
        "# input = {\n",
        "#     \"messages\": convert_to_messages(\n",
        "#         [\n",
        "#             {\n",
        "#                 \"role\": \"user\",\n",
        "#                 \"content\": \"Who are you?\",\n",
        "#             },\n",
        "#             {\n",
        "#                 \"role\": \"assistant\",\n",
        "#                 \"content\": \"\",\n",
        "#                 \"tool_calls\": [\n",
        "#                     {\n",
        "#                         \"id\": \"1\",\n",
        "#                         \"name\": \"retrieve_blog_posts\",\n",
        "#                         \"args\": {\"query\": \"Who are you?\"},\n",
        "#                     }\n",
        "#                 ],\n",
        "#             },\n",
        "#             {\n",
        "#                 \"role\": \"tool\",\n",
        "#                 \"content\": \"I am an AI language model created by OpenAI.\",\n",
        "#                 \"tool_call_id\": \"1\",\n",
        "#             },\n",
        "#         ]\n",
        "#     )\n",
        "# }\n",
        "\n",
        "# response = generate_answer(input)\n",
        "# response[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5_M-H7umVZD"
      },
      "source": [
        "**Assemble the graph**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KCWp_OmorXek"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition\n",
        "\n",
        "def build_agentic_graph(retriever_tool):\n",
        "    workflow = StateGraph(MessagesState)\n",
        "    # Add nodes\n",
        "    # def agent_node(state: MessagesState):\n",
        "    #     # LLM decides to answer or call a tool\n",
        "    #     return LLM.bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
        "    # def generate_query_or_respond(state):\n",
        "    #     response = ( \n",
        "    #     LLM\n",
        "    #     .bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
        "    #     )\n",
        "    #     return {\"messages\": [response]}\n",
        "    workflow.add_node(\"generate_query_or_respond\", make_generate_query_or_respond(retriever_tool))\n",
        "    # ToolNode handles retrieval\n",
        "    workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
        "    workflow.add_node(generate_answer)\n",
        "    # Edges\n",
        "    workflow.add_edge(START, \"generate_query_or_respond\")\n",
        "    workflow.add_conditional_edges(\n",
        "        \"generate_query_or_respond\",\n",
        "        # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
        "        tools_condition,\n",
        "        {\n",
        "            # Translate the condition outputs to nodes in our graph\n",
        "            \"tools\": \"retrieve\",\n",
        "            END: END,\n",
        "        },\n",
        "    )\n",
        "    workflow.add_edge(\"retrieve\", \"generate_answer\")\n",
        "    workflow.add_edge(\"generate_answer\", END)\n",
        "    # workflow.add_edge(\"retrieve\", \"agent\")  # cycle back for multiple tool use if needed\n",
        "    return workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langgraph.graph import StateGraph, START, END\n",
        "# from langgraph.prebuilt import ToolNode\n",
        "# from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# workflow = StateGraph(MessagesState)\n",
        "\n",
        "# # Define the nodes we will cycle between\n",
        "# workflow.add_node(generate_query_or_respond)\n",
        "# workflow.add_node(\"retrieve\", ToolNode([build_retriever_tool(vectordb)]))\n",
        "# # workflow.add_node(rewrite_question)\n",
        "# workflow.add_node(generate_answer)\n",
        "\n",
        "# workflow.add_edge(START, \"generate_query_or_respond\")\n",
        "\n",
        "# # Decide whether to retrieve\n",
        "# workflow.add_conditional_edges(\n",
        "#     \"generate_query_or_respond\",\n",
        "#     # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
        "#     tools_condition,\n",
        "#     {\n",
        "#         # Translate the condition outputs to nodes in our graph\n",
        "#         \"tools\": \"retrieve\",\n",
        "#         END: END,\n",
        "#     },\n",
        "# )\n",
        "\n",
        "# # Edges taken after the `action` node is called.\n",
        "# # workflow.add_conditional_edges(\n",
        "# #     \"retrieve\",\n",
        "# #     # Assess agent decision\n",
        "# #     grade_documents,\n",
        "# # )\n",
        "# workflow.add_edge(\"retrieve\",\"generate_answer\")\n",
        "# workflow.add_edge(\"generate_answer\", END)\n",
        "# # workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
        "\n",
        "# # Compile\n",
        "# graph = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7a6RjR4LVuFt"
      },
      "outputs": [],
      "source": [
        "# from langgraph.graph import START, MessagesState, StateGraph, END\n",
        "# from langgraph.prebuilt import tools_condition\n",
        "\n",
        "# def build_agentic_graph(retriever, retriever_tool):\n",
        "#     print(\"[INFO] Building agentic graph.\")\n",
        "#     g = StateGraph(MessagesState)\n",
        "#     g.add_node(\"agent\", generate_query_or_respond)\n",
        "#     g.add_node(\"retrieval\", run_retriever)\n",
        "#     g.add_node(\"generate_answer\", generate_answer)  # <- add this node\n",
        "\n",
        "#     g.add_edge(START, \"agent\")\n",
        "#     g.add_conditional_edges(\n",
        "#         \"agent\",\n",
        "#         should_retrieve,\n",
        "#         {\"needs_retrieval\": \"retrieval\", \"final\": END},\n",
        "#     )\n",
        "#     g.add_edge(\"retrieval\", \"generate_answer\")  # <- after retrieval, go to answer node\n",
        "#     g.add_edge(\"generate_answer\", END)          # <- after answer, finish\n",
        "\n",
        "#     graph = g.compile()\n",
        "#     graph.context = {\"retriever_tool\": retriever_tool, \"retriever\": retriever}\n",
        "#     return graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "VScN1midrgxX",
        "outputId": "dc8f5ffc-61ed-4b5d-d141-078820162892"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import Image, display\n",
        "\n",
        "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# # Now workflow is defined and can be used\n",
        "# # display(Image(workflow.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qooXzPQaro_S"
      },
      "outputs": [],
      "source": [
        "# def agentic_rag_query(pdf_bytes: bytes, filename: str, user_query: str):\n",
        "#     vectordb = load_or_create_chroma(pdf_bytes, filename)\n",
        "#     retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
        "#     retriever_tool = create_retriever_tool(\n",
        "#         retriever,\n",
        "#         name=\"search_pdf\",\n",
        "#         description=\"Look up relevant passages in the uploaded PDF.\",\n",
        "#     )\n",
        "#     graph = build_agentic_graph(retriever_tool)\n",
        "#     result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_query}]})\n",
        "#     answer = result[\"messages\"][-1].content\n",
        "#     return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "rB8W5yIsrt1K",
        "outputId": "d17a1a3f-ff26-4597-cca1-45f142031fa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\envs\\mcp_env\\lib\\site-packages\\gradio\\mcp.py:123: UserWarning: This MCP server includes a tool that has a gr.State input, which will not be updated between tool calls. The original, default value of the State will be used each time.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n",
            "\n",
            "ðŸ”¨ MCP server (using SSE) running at: http://127.0.0.1:7860/gradio_api/mcp/sse\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG: pdf_file type: <class 'gradio.utils.NamedString'>\n",
            "DEBUG: pdf_file dir: ['__add__', '__class__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__module__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'name', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n",
            "DEBUG: pdf_file repr: 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\c20bfafb09a6bcaf4ab5359e29617ec0f654f75810e7164f62a2753c926b0fd4\\\\LoRA.pdf'\n",
            "\n",
            "[INFO] Checking vectorstore for file: LoRA.pdf\n",
            "[INFO] Found existing vectorstore: C:\\Users\\USER\\.rag_vectors\\041bfb7673e530cb30510a4b147e4bca\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_28460\\3430095786.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  return Chroma(persist_directory=str(vect_dir), embedding_function=EMBEDDER)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk: {'generate_query_or_respond': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'function': {'arguments': '{\"query\": \"LoRA\"}', 'name': 'document_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 186, 'total_tokens': 207, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-77bbfa56c1d2415e9c3d8e559a0f2aea', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b9f0d415-aaaa-4257-8fbd-fed0b9e05173-0', tool_calls=[{'name': 'document_search', 'args': {'query': 'LoRA'}, 'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'type': 'tool_call'}], usage_metadata={'input_tokens': 186, 'output_tokens': 21, 'total_tokens': 207, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "Node: generate_query_or_respond, Update: {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'function': {'arguments': '{\"query\": \"LoRA\"}', 'name': 'document_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 186, 'total_tokens': 207, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-77bbfa56c1d2415e9c3d8e559a0f2aea', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b9f0d415-aaaa-4257-8fbd-fed0b9e05173-0', tool_calls=[{'name': 'document_search', 'args': {'query': 'LoRA'}, 'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'type': 'tool_call'}], usage_metadata={'input_tokens': 186, 'output_tokens': 21, 'total_tokens': 207, 'input_token_details': {}, 'output_token_details': {}})]}\n",
            "Chunk: {'retrieve': {'messages': [ToolMessage(content='TABLEI.Objectetectionresults(mAP)ofDiffusionDetmodelpretrainedonCOCO[4]andfine-tunedonDIOR[6]andDOTA[5]datasets\\nincross-domainfew-shotsettings.Wecomparethebaseline(noLoRA),LoRAwithdifferentranks(4,8,32,128),andLoRAappliedafter\\nintermediate fine-tuning. Best results per shot configuration are bold.\\nBaseline LoRA LoRA after a Fine-Tuning\\nDataset Shots\\n(no LoRA)\\n4 8 32 128 4 8 32 128\\n1 10.66 7.32 6.83 7.51 6.52 11.48 11.58 11.64 11.57\\n5 31.29 24.14 24.84 24.02 24.45 32.40 32.2 32.35 32.45\\nDIOR\\n10 41.50 34.72 34.25 33.91 33.23 40.64 40.68 40.81 41.18\\n50 59.71 56.43 53.41 53.24 56.47 57.72 57.74 57.78 57.70\\n1 4.23 1.86 1.81 1.81 1.70 4.89 4.85 4.84 4.97\\n5 22.52 15.17 14.83 15.15 14.73 22.75 22.83 22.91 22.85\\nDOTA\\n10 32.77 25.12 24.54 25.07 25.06 32.23 32.33 32.30 32.14\\n50 49.17 42.90 42.07 42.50 42.15 47.90 47.99 48.03 47.94\\nV. EXPERIMENTSANDRESULTS runs, we ensure a robust evaluation of LoRAâ€™s effectiveness\\nToevaluatetheeffectivenessofLoRAincross-domainfew- inmitigatingoverfittingandimprovinggeneralizationincross-\\nshot object detection, we conducted a series of experiments domain few-shot object detection.\\nusing the DiffusionDet framework. Our experiments were Across both datasets, the baseline outperforms direct\\ndesignedtoassesstheimpactofLoRAonmodelperformance, LoRA application in all shot configurations. However, LoRA\\noverfitting, and generalization across domains, particularly in applied after intermediate fine-tuning shows improvements,\\nthe challenging context of aerial images. particularly in low-shot settings. On DIOR, the best mAP of\\nWe used DiffusionDet model pre-trained on the COCO 11.64 (rank 32) is achieved in the 1-shot setting, while on\\ndataset, using the weights provided by the original authors DOTA,thebestmAPof4.97(rank128)isachieved.Similarly,\\n[10].Forthetargetdomains,weselectedtheDOTAandDIOR in the 5-shot setting, the best mAPs are 32.45 (rank 128) on\\ndatasets,whichwereconvertedtoCOCOformat1.Tosimulate DIOR and 22.91 (rank 32) on DOTA. In higher-shot settings,\\na few-shot setting, we randomly selected k images per class the baseline remains competitive, but LoRA after fine-tuning\\nfortraining,wherekrepresentsthenumberofshots.Toensure closely matches its performance.\\nafaircomparisonandaccountforvariabilityintheselectionof LoRA after intermediate fine-tuning slightly improves\\nimages,werepeatedeachexperiment5timesandreportedthe performance in low-shot settings, while the baseline remains\\naverage results. Given that DOTA images often contain more strong in higher-shot configurations. The choice of rank in\\nthan 100 objects, we set the maximum detection threshold to LoRA has a moderate impact on performance, with lower\\n300 in the pycocoapi evaluation toolkit [25]. ranks(e.g.,4,8)oftenperformingcomparablytohigherranks\\nAllexperimentswereconductedover300epochs,following (e.g., 32, 128).\\nthe training protocol established by the original DiffusionDet\\nauthors. We evaluated the model performance using the mean VI. DISCUSSION\\naverage precision (mAP) at an IoU threshold of 0.5, which is The experimental results demonstrate that LoRA,\\na standard metric for object detection tasks. For the baseline, particularly when applied after intermediate fine-tuning,\\nwe fine-tuned the pre-trained DiffusionDet model on the is a promising approach for cross-domain few-shot object\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\n\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\nthat lower ranks may suffice for many applications. However,\\nTo investigate the impact of rank selection on LoRAâ€™s\\nthebaselineâ€™sstrongperformanceinhigher-shotconfigurations\\nperformance, we tested four different ranks: 4, 8, 32, and\\nunderscores the importance of full fine-tuning when sufficient\\n128. The results of these experiments are presented in Tab.\\ndata is available. These results underline the need for a\\nI, which compares the performance of the baseline, direct\\nbalanced approach, adjusting the fine-tuning strategy to the\\nLoRA application, and LoRA after intermediate fine-tuning\\nspecificrequirementsofthetaskanddataset,andcouldbethe\\nacross different ranks. By averaging results across multiple\\nsubject of further study.\\nWhile our approach shows promise, it is not without\\n1Theycanbefoundhere:https://huggingface.co/datasets/HichTala/dota,\\nhttps://huggingface.co/datasets/HichTala/dior. limitations. The performance of LoRA depends on the quality\\n\\nAnalyzing the Impact of Low-Rank Adaptation for\\nCross-Domain Few-Shot Object Detection in Aerial\\nImages\\nHicham TALAOUBRID Anissa MOKRAOUI Ismail BEN AYED\\nL2TI & COSE L2TI LIVIA, ETS\\nUniversitÃ© Sorbonne Paris Nord UniversitÃ© Sorbonne Paris Nord Montreal, Canada\\nhicham.talaoubrid1@edu.univ-paris13.fr anissa.mokraoui@univ-paris13.fr Ismail.BenAyed@etsmtl.ca\\nAxel PROUVOST Sonimith HANG Monit KORN RÃ©mi HARVEY\\nIMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France COSE, Montmagny, France\\naxel.prouvost@etu.mines-ales.fr sonimith.hang@etu.mines-ales.fr monit.korn@etu.mines-ales.fr remi.harvey@cose.fr\\nAbstractâ€”This paper investigates the application of Low- domains, the problem becomes even more complex due\\nRank Adaptation (LoRA) to small models for cross-domain to significant distribution shifts between source and target\\nfew-shot object detection in aerial images. Originally designed\\ndomains. Traditional fine-tuning approaches often struggle in\\nfor large-scale models, LoRA helps mitigate overfitting, making\\nsuch scenarios as they tend to overfit to the limited training\\nit a promising approach for resource-constrained settings. We\\nintegrate LoRA into DiffusionDet, and evaluate its performance data,especiallyinsmallermodelswithfewerparameters.This\\non the DOTA and DIOR datasets. Our results show that challenge is even greater in cross-domain contexts, where the\\nLoRA applied after an initial fine-tuning slightly improves model needs to generalize to new domains with a minimum\\nperformance in low-shot settings (e.g., 1-shot and 5-shot),\\nof supervision.\\nwhile full fine-tuning remains more effective in higher-shot\\nconfigurations. These findings highlight LoRAâ€™s potential for\\nefficient adaptation in aerial object detection, encouraging\\nAerial images present an additional complexity for object\\nfurther research into parameter-efficient fine-tuning strategies\\ndetection. These images often contain numerous small\\nfor few-shot learning. Our code is available here: https://github.\\ncom/HichTala/LoRA-DiffusionDet objects densely distributed over the scene, as well as\\nIndex Termsâ€”Object Detection, Few-Shot Object Detection, significant variations in scale between classes, orientation,\\nDiffusion Models, Cross-Domain, Aerial Images, Low-rank and illumination [3]. These characteristics make aerial images\\nAdaptation. a particularly demanding domain for cross-domain few-shot\\nobject-detection.Themainproblemremainsoverfittinginsuch\\nI. INTRODUCTION a scenario. In this work, we investigate the application of\\nLoRA to small models, using the COCO [4] dataset as the\\nThe last few years have seen remarkable improvement\\nsource domain and the DOTA [5] and DIOR [6] datasets as\\nin large models. Particularly in natural language processing\\ntargetdomains.Bothdatasetsarewidelyrecognizedreferences\\nand computer vision [1] [2]. Parameter-efficient fine-tuning\\nfor aerial image analysis [7] [8].\\nmethodshavebeendevelopedtotraintheseverylargemodels\\nfor simpler tasks, without the need to train tens of billions of\\nparameters. One of these is Low Rank Adaptation (LoRA), The motivation behind this work is to address overfitting\\nwhich, by injecting low rank matrices while freezing the in cross-domain few-shot object detection, particularly for\\nmodelâ€™spre-trainingweights,considerablyreducesthenumber aerial images. We explore Low-Rank Adaptation (LoRA)\\nof parameters to be trained in the model. In this way, [9], a technique designed for large models, to improve\\nLoRA helps to limit the overfitting of large models by generalization in smaller architectures like DiffusionDet [10],\\nacceleratingtheirconvergence.Butitspotentialinmodels100 which has about millions of parameters. DiffusionDet has\\nto 1000 times smaller in terms of parameters remains rather shown effectiveness in detecting small objects, making it a\\nunexplored, particularly in a context of cross domain few- goodchoiceforaerialimages.WecompareDiffusionDetwith\\nshot object detection, where the overfitting remains the main and without LoRA, testing two strategies: (1) direct LoRA\\ndifficulty. applicationand(2)LoRAafterintermediatefine-tuning.Using\\nFew-shot Object Detection (FSOD) is a challenging theDOTAandDIORdatasets,weevaluatedLoRAâ€™sabilityto\\ntask that aims to detect objects from novel categories reduce overfitting and improve generalization, offering insight\\nusing only a few labeled examples. When applied across intoitspotentialforefficientandrobustaerialobjectdetection.\\n5202\\nrpA\\n8\\n]VC.sc[\\n1v03360.4052:viXra\\n\\nof the initial fine-tuning. Additionally, our experiments are [7] Z. Chen, H. Wang, X. Wu, J. Wang, X. Lin, C. Wang, K. Gao,\\nlimited to DiffusionDet and two aerial datasets; extending M.Chapman,andD.Li,â€œObjectdetectioninaerialimagesusingdota\\ndataset:Asurvey,â€InternationalJournalofAppliedEarthObservation\\nthis approach to other architectures and domains could\\nand Geoinformation, vol. 134, p. 104208, 2024. [Online]. Available:\\nyield further insights. Future work could explore combining https://www.sciencedirect.com/science/article/pii/S1569843224005648\\nLoRA with other few-shot learning techniques to enhance its [8] J. Leng, Y. Ye, M. Mo, C. Gao, J. Gan, B. Xiao, and X. Gao,\\nâ€œRecentadvancesforaerialobjectdetection:Asurvey,â€ACMComputing\\neffectiveness.\\nSurveys,vol.56,no.12,pp.1â€“36,2024.\\nIt is worth noting that the cross-domain scenario explored [9] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang,\\nin this workâ€”adapting from natural images (COCO) to aerial and W. Chen, â€œLora: Low-rank adaptation of large language\\nmodels,â€ CoRR, vol. abs/2106.09685, 2021. [Online]. Available:\\nimages (DOTA and DIOR), remains particularly challenging\\nhttps://arxiv.org/abs/2106.09685\\ndue to the significant differences in perspective, scale, and [10] S. Chen, P. Sun, Y. Song, and P. Luo, â€œDiffusiondet: Diffusion model\\n[11] Y.Wang,R.Zhangetal.,â€œLow-rankadaptationforvisiontransformers\\nwould involve adapting between aerial images, such as from\\nDOTAtoDIORorviceversa,wherethedomainshiftsareless [12] L. H. Li, P. Zhang, H. Zhang, J. Yang, C. Li, Y. Zhong,\\nextreme.Onecouldalsoexploreadaptingaerialimagesacross L. Wang, L. Yuan, L. Zhang, J. Hwang, K. Chang, and J. Gao,\\nâ€œGrounded language-image pre-training,â€ CoRR, vol. abs/2112.03857,\\ndifferent environments, seasons, or lighting conditions. Such\\n2021.[Online].Available:https://arxiv.org/abs/2112.03857\\nexperimentscouldprovidevaluableinsightsintotherobustness [13] M.Kohler,M.Eisenbach,andH.-M.Gross,â€œFew-shotobjectdetection:\\nand versatility of LoRA in less extreme domain shifts. A comprehensive survey,â€ IEEE transactions on neural networks and\\nlearningsystems,2021.\\n[14] C. Finn, P. Abbeel, and S. Levine, â€œModel-agnostic meta-learning\\nVII. CONCLUSION for fast adaptation of deep networks,â€ in International Conference on\\nMachineLearning. PMLR,2017,pp.1126â€“1135.\\nIn this work, we investigated the application of LoRA [15] W. Xiong, â€œCd-fsod: A benchmark for cross-domain few-shot object\\nto DiffusionDet model for cross-domain few-shot object detection,â€ in ICASSP 2023-2023 IEEE International Conference on\\nAcoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp.\\ndetection, with a focus on the challenging domain of aerial\\n1â€“5.\\nimages. Using the DiffusionDet framework, we evaluated the [16] K. Lee, H. Yang, S. Chakraborty, Z. Cai, G. Swaminathan,\\neffectivenessofLoRAinmitigatingoverfittingandimproving A.Ravichandran,andO.Dabeer,â€œRethinkingfew-shotobjectdetection\\non a multi-domain benchmark,â€ in Computer Visionâ€“ECCV 2022:\\ngeneralization across the DOTA and DIOR datasets. Our\\n17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022,\\nexperiments compared three approaches: (1) baseline fine- Proceedings,PartXX. Springer,2022,pp.366â€“382.\\ntuning, (2) direct LoRA application, and (3) LoRA applied [17] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, â€œAdversarial\\ndiscriminative domain adaptation,â€ in Proceedings of the IEEE\\nafter intermediate fine-tuning. The results demonstrated that\\nconferenceoncomputervisionandpatternrecognition,2017,pp.7167â€“\\nwhile the baseline outperformed direct LoRA application, 7176.\\nLoRA after intermediate fine-tuning achieved competitive [18] T.-Y.Lin,P.DollÃ¡r,R.Girshick,K.He,B.Hariharan,andS.Belongie,', name='document_search', id='f8d24484-6afa-4b42-8dd6-43bb46610dad', tool_call_id='chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231')]}}\n",
            "Node: retrieve, Update: {'messages': [ToolMessage(content='TABLEI.Objectetectionresults(mAP)ofDiffusionDetmodelpretrainedonCOCO[4]andfine-tunedonDIOR[6]andDOTA[5]datasets\\nincross-domainfew-shotsettings.Wecomparethebaseline(noLoRA),LoRAwithdifferentranks(4,8,32,128),andLoRAappliedafter\\nintermediate fine-tuning. Best results per shot configuration are bold.\\nBaseline LoRA LoRA after a Fine-Tuning\\nDataset Shots\\n(no LoRA)\\n4 8 32 128 4 8 32 128\\n1 10.66 7.32 6.83 7.51 6.52 11.48 11.58 11.64 11.57\\n5 31.29 24.14 24.84 24.02 24.45 32.40 32.2 32.35 32.45\\nDIOR\\n10 41.50 34.72 34.25 33.91 33.23 40.64 40.68 40.81 41.18\\n50 59.71 56.43 53.41 53.24 56.47 57.72 57.74 57.78 57.70\\n1 4.23 1.86 1.81 1.81 1.70 4.89 4.85 4.84 4.97\\n5 22.52 15.17 14.83 15.15 14.73 22.75 22.83 22.91 22.85\\nDOTA\\n10 32.77 25.12 24.54 25.07 25.06 32.23 32.33 32.30 32.14\\n50 49.17 42.90 42.07 42.50 42.15 47.90 47.99 48.03 47.94\\nV. EXPERIMENTSANDRESULTS runs, we ensure a robust evaluation of LoRAâ€™s effectiveness\\nToevaluatetheeffectivenessofLoRAincross-domainfew- inmitigatingoverfittingandimprovinggeneralizationincross-\\nshot object detection, we conducted a series of experiments domain few-shot object detection.\\nusing the DiffusionDet framework. Our experiments were Across both datasets, the baseline outperforms direct\\ndesignedtoassesstheimpactofLoRAonmodelperformance, LoRA application in all shot configurations. However, LoRA\\noverfitting, and generalization across domains, particularly in applied after intermediate fine-tuning shows improvements,\\nthe challenging context of aerial images. particularly in low-shot settings. On DIOR, the best mAP of\\nWe used DiffusionDet model pre-trained on the COCO 11.64 (rank 32) is achieved in the 1-shot setting, while on\\ndataset, using the weights provided by the original authors DOTA,thebestmAPof4.97(rank128)isachieved.Similarly,\\n[10].Forthetargetdomains,weselectedtheDOTAandDIOR in the 5-shot setting, the best mAPs are 32.45 (rank 128) on\\ndatasets,whichwereconvertedtoCOCOformat1.Tosimulate DIOR and 22.91 (rank 32) on DOTA. In higher-shot settings,\\na few-shot setting, we randomly selected k images per class the baseline remains competitive, but LoRA after fine-tuning\\nfortraining,wherekrepresentsthenumberofshots.Toensure closely matches its performance.\\nafaircomparisonandaccountforvariabilityintheselectionof LoRA after intermediate fine-tuning slightly improves\\nimages,werepeatedeachexperiment5timesandreportedthe performance in low-shot settings, while the baseline remains\\naverage results. Given that DOTA images often contain more strong in higher-shot configurations. The choice of rank in\\nthan 100 objects, we set the maximum detection threshold to LoRA has a moderate impact on performance, with lower\\n300 in the pycocoapi evaluation toolkit [25]. ranks(e.g.,4,8)oftenperformingcomparablytohigherranks\\nAllexperimentswereconductedover300epochs,following (e.g., 32, 128).\\nthe training protocol established by the original DiffusionDet\\nauthors. We evaluated the model performance using the mean VI. DISCUSSION\\naverage precision (mAP) at an IoU threshold of 0.5, which is The experimental results demonstrate that LoRA,\\na standard metric for object detection tasks. For the baseline, particularly when applied after intermediate fine-tuning,\\nwe fine-tuned the pre-trained DiffusionDet model on the is a promising approach for cross-domain few-shot object\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\n\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\nthat lower ranks may suffice for many applications. However,\\nTo investigate the impact of rank selection on LoRAâ€™s\\nthebaselineâ€™sstrongperformanceinhigher-shotconfigurations\\nperformance, we tested four different ranks: 4, 8, 32, and\\nunderscores the importance of full fine-tuning when sufficient\\n128. The results of these experiments are presented in Tab.\\ndata is available. These results underline the need for a\\nI, which compares the performance of the baseline, direct\\nbalanced approach, adjusting the fine-tuning strategy to the\\nLoRA application, and LoRA after intermediate fine-tuning\\nspecificrequirementsofthetaskanddataset,andcouldbethe\\nacross different ranks. By averaging results across multiple\\nsubject of further study.\\nWhile our approach shows promise, it is not without\\n1Theycanbefoundhere:https://huggingface.co/datasets/HichTala/dota,\\nhttps://huggingface.co/datasets/HichTala/dior. limitations. The performance of LoRA depends on the quality\\n\\nAnalyzing the Impact of Low-Rank Adaptation for\\nCross-Domain Few-Shot Object Detection in Aerial\\nImages\\nHicham TALAOUBRID Anissa MOKRAOUI Ismail BEN AYED\\nL2TI & COSE L2TI LIVIA, ETS\\nUniversitÃ© Sorbonne Paris Nord UniversitÃ© Sorbonne Paris Nord Montreal, Canada\\nhicham.talaoubrid1@edu.univ-paris13.fr anissa.mokraoui@univ-paris13.fr Ismail.BenAyed@etsmtl.ca\\nAxel PROUVOST Sonimith HANG Monit KORN RÃ©mi HARVEY\\nIMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France COSE, Montmagny, France\\naxel.prouvost@etu.mines-ales.fr sonimith.hang@etu.mines-ales.fr monit.korn@etu.mines-ales.fr remi.harvey@cose.fr\\nAbstractâ€”This paper investigates the application of Low- domains, the problem becomes even more complex due\\nRank Adaptation (LoRA) to small models for cross-domain to significant distribution shifts between source and target\\nfew-shot object detection in aerial images. Originally designed\\ndomains. Traditional fine-tuning approaches often struggle in\\nfor large-scale models, LoRA helps mitigate overfitting, making\\nsuch scenarios as they tend to overfit to the limited training\\nit a promising approach for resource-constrained settings. We\\nintegrate LoRA into DiffusionDet, and evaluate its performance data,especiallyinsmallermodelswithfewerparameters.This\\non the DOTA and DIOR datasets. Our results show that challenge is even greater in cross-domain contexts, where the\\nLoRA applied after an initial fine-tuning slightly improves model needs to generalize to new domains with a minimum\\nperformance in low-shot settings (e.g., 1-shot and 5-shot),\\nof supervision.\\nwhile full fine-tuning remains more effective in higher-shot\\nconfigurations. These findings highlight LoRAâ€™s potential for\\nefficient adaptation in aerial object detection, encouraging\\nAerial images present an additional complexity for object\\nfurther research into parameter-efficient fine-tuning strategies\\ndetection. These images often contain numerous small\\nfor few-shot learning. Our code is available here: https://github.\\ncom/HichTala/LoRA-DiffusionDet objects densely distributed over the scene, as well as\\nIndex Termsâ€”Object Detection, Few-Shot Object Detection, significant variations in scale between classes, orientation,\\nDiffusion Models, Cross-Domain, Aerial Images, Low-rank and illumination [3]. These characteristics make aerial images\\nAdaptation. a particularly demanding domain for cross-domain few-shot\\nobject-detection.Themainproblemremainsoverfittinginsuch\\nI. INTRODUCTION a scenario. In this work, we investigate the application of\\nLoRA to small models, using the COCO [4] dataset as the\\nThe last few years have seen remarkable improvement\\nsource domain and the DOTA [5] and DIOR [6] datasets as\\nin large models. Particularly in natural language processing\\ntargetdomains.Bothdatasetsarewidelyrecognizedreferences\\nand computer vision [1] [2]. Parameter-efficient fine-tuning\\nfor aerial image analysis [7] [8].\\nmethodshavebeendevelopedtotraintheseverylargemodels\\nfor simpler tasks, without the need to train tens of billions of\\nparameters. One of these is Low Rank Adaptation (LoRA), The motivation behind this work is to address overfitting\\nwhich, by injecting low rank matrices while freezing the in cross-domain few-shot object detection, particularly for\\nmodelâ€™spre-trainingweights,considerablyreducesthenumber aerial images. We explore Low-Rank Adaptation (LoRA)\\nof parameters to be trained in the model. In this way, [9], a technique designed for large models, to improve\\nLoRA helps to limit the overfitting of large models by generalization in smaller architectures like DiffusionDet [10],\\nacceleratingtheirconvergence.Butitspotentialinmodels100 which has about millions of parameters. DiffusionDet has\\nto 1000 times smaller in terms of parameters remains rather shown effectiveness in detecting small objects, making it a\\nunexplored, particularly in a context of cross domain few- goodchoiceforaerialimages.WecompareDiffusionDetwith\\nshot object detection, where the overfitting remains the main and without LoRA, testing two strategies: (1) direct LoRA\\ndifficulty. applicationand(2)LoRAafterintermediatefine-tuning.Using\\nFew-shot Object Detection (FSOD) is a challenging theDOTAandDIORdatasets,weevaluatedLoRAâ€™sabilityto\\ntask that aims to detect objects from novel categories reduce overfitting and improve generalization, offering insight\\nusing only a few labeled examples. When applied across intoitspotentialforefficientandrobustaerialobjectdetection.\\n5202\\nrpA\\n8\\n]VC.sc[\\n1v03360.4052:viXra\\n\\nof the initial fine-tuning. Additionally, our experiments are [7] Z. Chen, H. Wang, X. Wu, J. Wang, X. Lin, C. Wang, K. Gao,\\nlimited to DiffusionDet and two aerial datasets; extending M.Chapman,andD.Li,â€œObjectdetectioninaerialimagesusingdota\\ndataset:Asurvey,â€InternationalJournalofAppliedEarthObservation\\nthis approach to other architectures and domains could\\nand Geoinformation, vol. 134, p. 104208, 2024. [Online]. Available:\\nyield further insights. Future work could explore combining https://www.sciencedirect.com/science/article/pii/S1569843224005648\\nLoRA with other few-shot learning techniques to enhance its [8] J. Leng, Y. Ye, M. Mo, C. Gao, J. Gan, B. Xiao, and X. Gao,\\nâ€œRecentadvancesforaerialobjectdetection:Asurvey,â€ACMComputing\\neffectiveness.\\nSurveys,vol.56,no.12,pp.1â€“36,2024.\\nIt is worth noting that the cross-domain scenario explored [9] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang,\\nin this workâ€”adapting from natural images (COCO) to aerial and W. Chen, â€œLora: Low-rank adaptation of large language\\nmodels,â€ CoRR, vol. abs/2106.09685, 2021. [Online]. Available:\\nimages (DOTA and DIOR), remains particularly challenging\\nhttps://arxiv.org/abs/2106.09685\\ndue to the significant differences in perspective, scale, and [10] S. Chen, P. Sun, Y. Song, and P. Luo, â€œDiffusiondet: Diffusion model\\n[11] Y.Wang,R.Zhangetal.,â€œLow-rankadaptationforvisiontransformers\\nwould involve adapting between aerial images, such as from\\nDOTAtoDIORorviceversa,wherethedomainshiftsareless [12] L. H. Li, P. Zhang, H. Zhang, J. Yang, C. Li, Y. Zhong,\\nextreme.Onecouldalsoexploreadaptingaerialimagesacross L. Wang, L. Yuan, L. Zhang, J. Hwang, K. Chang, and J. Gao,\\nâ€œGrounded language-image pre-training,â€ CoRR, vol. abs/2112.03857,\\ndifferent environments, seasons, or lighting conditions. Such\\n2021.[Online].Available:https://arxiv.org/abs/2112.03857\\nexperimentscouldprovidevaluableinsightsintotherobustness [13] M.Kohler,M.Eisenbach,andH.-M.Gross,â€œFew-shotobjectdetection:\\nand versatility of LoRA in less extreme domain shifts. A comprehensive survey,â€ IEEE transactions on neural networks and\\nlearningsystems,2021.\\n[14] C. Finn, P. Abbeel, and S. Levine, â€œModel-agnostic meta-learning\\nVII. CONCLUSION for fast adaptation of deep networks,â€ in International Conference on\\nMachineLearning. PMLR,2017,pp.1126â€“1135.\\nIn this work, we investigated the application of LoRA [15] W. Xiong, â€œCd-fsod: A benchmark for cross-domain few-shot object\\nto DiffusionDet model for cross-domain few-shot object detection,â€ in ICASSP 2023-2023 IEEE International Conference on\\nAcoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp.\\ndetection, with a focus on the challenging domain of aerial\\n1â€“5.\\nimages. Using the DiffusionDet framework, we evaluated the [16] K. Lee, H. Yang, S. Chakraborty, Z. Cai, G. Swaminathan,\\neffectivenessofLoRAinmitigatingoverfittingandimproving A.Ravichandran,andO.Dabeer,â€œRethinkingfew-shotobjectdetection\\non a multi-domain benchmark,â€ in Computer Visionâ€“ECCV 2022:\\ngeneralization across the DOTA and DIOR datasets. Our\\n17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022,\\nexperiments compared three approaches: (1) baseline fine- Proceedings,PartXX. Springer,2022,pp.366â€“382.\\ntuning, (2) direct LoRA application, and (3) LoRA applied [17] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, â€œAdversarial\\ndiscriminative domain adaptation,â€ in Proceedings of the IEEE\\nafter intermediate fine-tuning. The results demonstrated that\\nconferenceoncomputervisionandpatternrecognition,2017,pp.7167â€“\\nwhile the baseline outperformed direct LoRA application, 7176.\\nLoRA after intermediate fine-tuning achieved competitive [18] T.-Y.Lin,P.DollÃ¡r,R.Girshick,K.He,B.Hariharan,andS.Belongie,', name='document_search', id='f8d24484-6afa-4b42-8dd6-43bb46610dad', tool_call_id='chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231')]}\n",
            "[DEBUG] Answer node, messages so far: [HumanMessage(content='what is LoRA, please use the tool?', additional_kwargs={}, response_metadata={}, id='0d20d1b2-a60f-4f8d-a459-e984b0792249'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'function': {'arguments': '{\"query\": \"LoRA\"}', 'name': 'document_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 186, 'total_tokens': 207, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-77bbfa56c1d2415e9c3d8e559a0f2aea', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b9f0d415-aaaa-4257-8fbd-fed0b9e05173-0', tool_calls=[{'name': 'document_search', 'args': {'query': 'LoRA'}, 'id': 'chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231', 'type': 'tool_call'}], usage_metadata={'input_tokens': 186, 'output_tokens': 21, 'total_tokens': 207, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='TABLEI.Objectetectionresults(mAP)ofDiffusionDetmodelpretrainedonCOCO[4]andfine-tunedonDIOR[6]andDOTA[5]datasets\\nincross-domainfew-shotsettings.Wecomparethebaseline(noLoRA),LoRAwithdifferentranks(4,8,32,128),andLoRAappliedafter\\nintermediate fine-tuning. Best results per shot configuration are bold.\\nBaseline LoRA LoRA after a Fine-Tuning\\nDataset Shots\\n(no LoRA)\\n4 8 32 128 4 8 32 128\\n1 10.66 7.32 6.83 7.51 6.52 11.48 11.58 11.64 11.57\\n5 31.29 24.14 24.84 24.02 24.45 32.40 32.2 32.35 32.45\\nDIOR\\n10 41.50 34.72 34.25 33.91 33.23 40.64 40.68 40.81 41.18\\n50 59.71 56.43 53.41 53.24 56.47 57.72 57.74 57.78 57.70\\n1 4.23 1.86 1.81 1.81 1.70 4.89 4.85 4.84 4.97\\n5 22.52 15.17 14.83 15.15 14.73 22.75 22.83 22.91 22.85\\nDOTA\\n10 32.77 25.12 24.54 25.07 25.06 32.23 32.33 32.30 32.14\\n50 49.17 42.90 42.07 42.50 42.15 47.90 47.99 48.03 47.94\\nV. EXPERIMENTSANDRESULTS runs, we ensure a robust evaluation of LoRAâ€™s effectiveness\\nToevaluatetheeffectivenessofLoRAincross-domainfew- inmitigatingoverfittingandimprovinggeneralizationincross-\\nshot object detection, we conducted a series of experiments domain few-shot object detection.\\nusing the DiffusionDet framework. Our experiments were Across both datasets, the baseline outperforms direct\\ndesignedtoassesstheimpactofLoRAonmodelperformance, LoRA application in all shot configurations. However, LoRA\\noverfitting, and generalization across domains, particularly in applied after intermediate fine-tuning shows improvements,\\nthe challenging context of aerial images. particularly in low-shot settings. On DIOR, the best mAP of\\nWe used DiffusionDet model pre-trained on the COCO 11.64 (rank 32) is achieved in the 1-shot setting, while on\\ndataset, using the weights provided by the original authors DOTA,thebestmAPof4.97(rank128)isachieved.Similarly,\\n[10].Forthetargetdomains,weselectedtheDOTAandDIOR in the 5-shot setting, the best mAPs are 32.45 (rank 128) on\\ndatasets,whichwereconvertedtoCOCOformat1.Tosimulate DIOR and 22.91 (rank 32) on DOTA. In higher-shot settings,\\na few-shot setting, we randomly selected k images per class the baseline remains competitive, but LoRA after fine-tuning\\nfortraining,wherekrepresentsthenumberofshots.Toensure closely matches its performance.\\nafaircomparisonandaccountforvariabilityintheselectionof LoRA after intermediate fine-tuning slightly improves\\nimages,werepeatedeachexperiment5timesandreportedthe performance in low-shot settings, while the baseline remains\\naverage results. Given that DOTA images often contain more strong in higher-shot configurations. The choice of rank in\\nthan 100 objects, we set the maximum detection threshold to LoRA has a moderate impact on performance, with lower\\n300 in the pycocoapi evaluation toolkit [25]. ranks(e.g.,4,8)oftenperformingcomparablytohigherranks\\nAllexperimentswereconductedover300epochs,following (e.g., 32, 128).\\nthe training protocol established by the original DiffusionDet\\nauthors. We evaluated the model performance using the mean VI. DISCUSSION\\naverage precision (mAP) at an IoU threshold of 0.5, which is The experimental results demonstrate that LoRA,\\na standard metric for object detection tasks. For the baseline, particularly when applied after intermediate fine-tuning,\\nwe fine-tuned the pre-trained DiffusionDet model on the is a promising approach for cross-domain few-shot object\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\n\\nfew-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\\nparameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\\nexperiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\\ndirectly to the pre-trained model and applying LoRA to the environments.\\nbest checkpoint obtained from the baseline fine-tuning. In the\\nThe choice of rank in LoRA has a moderate impact on\\nlatter approach, we selected the checkpoint with the highest\\nperformance, with lower ranks (e.g., 4, 8) often performing\\nvalidation performance after 300 epochs and fine-tuned it\\ncomparably to higher ranks (e.g., 32, 128). This indicates\\nfurther using LoRA.\\nthat lower ranks may suffice for many applications. However,\\nTo investigate the impact of rank selection on LoRAâ€™s\\nthebaselineâ€™sstrongperformanceinhigher-shotconfigurations\\nperformance, we tested four different ranks: 4, 8, 32, and\\nunderscores the importance of full fine-tuning when sufficient\\n128. The results of these experiments are presented in Tab.\\ndata is available. These results underline the need for a\\nI, which compares the performance of the baseline, direct\\nbalanced approach, adjusting the fine-tuning strategy to the\\nLoRA application, and LoRA after intermediate fine-tuning\\nspecificrequirementsofthetaskanddataset,andcouldbethe\\nacross different ranks. By averaging results across multiple\\nsubject of further study.\\nWhile our approach shows promise, it is not without\\n1Theycanbefoundhere:https://huggingface.co/datasets/HichTala/dota,\\nhttps://huggingface.co/datasets/HichTala/dior. limitations. The performance of LoRA depends on the quality\\n\\nAnalyzing the Impact of Low-Rank Adaptation for\\nCross-Domain Few-Shot Object Detection in Aerial\\nImages\\nHicham TALAOUBRID Anissa MOKRAOUI Ismail BEN AYED\\nL2TI & COSE L2TI LIVIA, ETS\\nUniversitÃ© Sorbonne Paris Nord UniversitÃ© Sorbonne Paris Nord Montreal, Canada\\nhicham.talaoubrid1@edu.univ-paris13.fr anissa.mokraoui@univ-paris13.fr Ismail.BenAyed@etsmtl.ca\\nAxel PROUVOST Sonimith HANG Monit KORN RÃ©mi HARVEY\\nIMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France COSE, Montmagny, France\\naxel.prouvost@etu.mines-ales.fr sonimith.hang@etu.mines-ales.fr monit.korn@etu.mines-ales.fr remi.harvey@cose.fr\\nAbstractâ€”This paper investigates the application of Low- domains, the problem becomes even more complex due\\nRank Adaptation (LoRA) to small models for cross-domain to significant distribution shifts between source and target\\nfew-shot object detection in aerial images. Originally designed\\ndomains. Traditional fine-tuning approaches often struggle in\\nfor large-scale models, LoRA helps mitigate overfitting, making\\nsuch scenarios as they tend to overfit to the limited training\\nit a promising approach for resource-constrained settings. We\\nintegrate LoRA into DiffusionDet, and evaluate its performance data,especiallyinsmallermodelswithfewerparameters.This\\non the DOTA and DIOR datasets. Our results show that challenge is even greater in cross-domain contexts, where the\\nLoRA applied after an initial fine-tuning slightly improves model needs to generalize to new domains with a minimum\\nperformance in low-shot settings (e.g., 1-shot and 5-shot),\\nof supervision.\\nwhile full fine-tuning remains more effective in higher-shot\\nconfigurations. These findings highlight LoRAâ€™s potential for\\nefficient adaptation in aerial object detection, encouraging\\nAerial images present an additional complexity for object\\nfurther research into parameter-efficient fine-tuning strategies\\ndetection. These images often contain numerous small\\nfor few-shot learning. Our code is available here: https://github.\\ncom/HichTala/LoRA-DiffusionDet objects densely distributed over the scene, as well as\\nIndex Termsâ€”Object Detection, Few-Shot Object Detection, significant variations in scale between classes, orientation,\\nDiffusion Models, Cross-Domain, Aerial Images, Low-rank and illumination [3]. These characteristics make aerial images\\nAdaptation. a particularly demanding domain for cross-domain few-shot\\nobject-detection.Themainproblemremainsoverfittinginsuch\\nI. INTRODUCTION a scenario. In this work, we investigate the application of\\nLoRA to small models, using the COCO [4] dataset as the\\nThe last few years have seen remarkable improvement\\nsource domain and the DOTA [5] and DIOR [6] datasets as\\nin large models. Particularly in natural language processing\\ntargetdomains.Bothdatasetsarewidelyrecognizedreferences\\nand computer vision [1] [2]. Parameter-efficient fine-tuning\\nfor aerial image analysis [7] [8].\\nmethodshavebeendevelopedtotraintheseverylargemodels\\nfor simpler tasks, without the need to train tens of billions of\\nparameters. One of these is Low Rank Adaptation (LoRA), The motivation behind this work is to address overfitting\\nwhich, by injecting low rank matrices while freezing the in cross-domain few-shot object detection, particularly for\\nmodelâ€™spre-trainingweights,considerablyreducesthenumber aerial images. We explore Low-Rank Adaptation (LoRA)\\nof parameters to be trained in the model. In this way, [9], a technique designed for large models, to improve\\nLoRA helps to limit the overfitting of large models by generalization in smaller architectures like DiffusionDet [10],\\nacceleratingtheirconvergence.Butitspotentialinmodels100 which has about millions of parameters. DiffusionDet has\\nto 1000 times smaller in terms of parameters remains rather shown effectiveness in detecting small objects, making it a\\nunexplored, particularly in a context of cross domain few- goodchoiceforaerialimages.WecompareDiffusionDetwith\\nshot object detection, where the overfitting remains the main and without LoRA, testing two strategies: (1) direct LoRA\\ndifficulty. applicationand(2)LoRAafterintermediatefine-tuning.Using\\nFew-shot Object Detection (FSOD) is a challenging theDOTAandDIORdatasets,weevaluatedLoRAâ€™sabilityto\\ntask that aims to detect objects from novel categories reduce overfitting and improve generalization, offering insight\\nusing only a few labeled examples. When applied across intoitspotentialforefficientandrobustaerialobjectdetection.\\n5202\\nrpA\\n8\\n]VC.sc[\\n1v03360.4052:viXra\\n\\nof the initial fine-tuning. Additionally, our experiments are [7] Z. Chen, H. Wang, X. Wu, J. Wang, X. Lin, C. Wang, K. Gao,\\nlimited to DiffusionDet and two aerial datasets; extending M.Chapman,andD.Li,â€œObjectdetectioninaerialimagesusingdota\\ndataset:Asurvey,â€InternationalJournalofAppliedEarthObservation\\nthis approach to other architectures and domains could\\nand Geoinformation, vol. 134, p. 104208, 2024. [Online]. Available:\\nyield further insights. Future work could explore combining https://www.sciencedirect.com/science/article/pii/S1569843224005648\\nLoRA with other few-shot learning techniques to enhance its [8] J. Leng, Y. Ye, M. Mo, C. Gao, J. Gan, B. Xiao, and X. Gao,\\nâ€œRecentadvancesforaerialobjectdetection:Asurvey,â€ACMComputing\\neffectiveness.\\nSurveys,vol.56,no.12,pp.1â€“36,2024.\\nIt is worth noting that the cross-domain scenario explored [9] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang,\\nin this workâ€”adapting from natural images (COCO) to aerial and W. Chen, â€œLora: Low-rank adaptation of large language\\nmodels,â€ CoRR, vol. abs/2106.09685, 2021. [Online]. Available:\\nimages (DOTA and DIOR), remains particularly challenging\\nhttps://arxiv.org/abs/2106.09685\\ndue to the significant differences in perspective, scale, and [10] S. Chen, P. Sun, Y. Song, and P. Luo, â€œDiffusiondet: Diffusion model\\n[11] Y.Wang,R.Zhangetal.,â€œLow-rankadaptationforvisiontransformers\\nwould involve adapting between aerial images, such as from\\nDOTAtoDIORorviceversa,wherethedomainshiftsareless [12] L. H. Li, P. Zhang, H. Zhang, J. Yang, C. Li, Y. Zhong,\\nextreme.Onecouldalsoexploreadaptingaerialimagesacross L. Wang, L. Yuan, L. Zhang, J. Hwang, K. Chang, and J. Gao,\\nâ€œGrounded language-image pre-training,â€ CoRR, vol. abs/2112.03857,\\ndifferent environments, seasons, or lighting conditions. Such\\n2021.[Online].Available:https://arxiv.org/abs/2112.03857\\nexperimentscouldprovidevaluableinsightsintotherobustness [13] M.Kohler,M.Eisenbach,andH.-M.Gross,â€œFew-shotobjectdetection:\\nand versatility of LoRA in less extreme domain shifts. A comprehensive survey,â€ IEEE transactions on neural networks and\\nlearningsystems,2021.\\n[14] C. Finn, P. Abbeel, and S. Levine, â€œModel-agnostic meta-learning\\nVII. CONCLUSION for fast adaptation of deep networks,â€ in International Conference on\\nMachineLearning. PMLR,2017,pp.1126â€“1135.\\nIn this work, we investigated the application of LoRA [15] W. Xiong, â€œCd-fsod: A benchmark for cross-domain few-shot object\\nto DiffusionDet model for cross-domain few-shot object detection,â€ in ICASSP 2023-2023 IEEE International Conference on\\nAcoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp.\\ndetection, with a focus on the challenging domain of aerial\\n1â€“5.\\nimages. Using the DiffusionDet framework, we evaluated the [16] K. Lee, H. Yang, S. Chakraborty, Z. Cai, G. Swaminathan,\\neffectivenessofLoRAinmitigatingoverfittingandimproving A.Ravichandran,andO.Dabeer,â€œRethinkingfew-shotobjectdetection\\non a multi-domain benchmark,â€ in Computer Visionâ€“ECCV 2022:\\ngeneralization across the DOTA and DIOR datasets. Our\\n17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022,\\nexperiments compared three approaches: (1) baseline fine- Proceedings,PartXX. Springer,2022,pp.366â€“382.\\ntuning, (2) direct LoRA application, and (3) LoRA applied [17] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, â€œAdversarial\\ndiscriminative domain adaptation,â€ in Proceedings of the IEEE\\nafter intermediate fine-tuning. The results demonstrated that\\nconferenceoncomputervisionandpatternrecognition,2017,pp.7167â€“\\nwhile the baseline outperformed direct LoRA application, 7176.\\nLoRA after intermediate fine-tuning achieved competitive [18] T.-Y.Lin,P.DollÃ¡r,R.Girshick,K.He,B.Hariharan,andS.Belongie,', name='document_search', id='f8d24484-6afa-4b42-8dd6-43bb46610dad', tool_call_id='chatcmpl-tool-c1a940c7b923451898e4c2f57b7db231')]\n",
            "[DEBUG] Question: what is LoRA, please use the tool?\n",
            "[DEBUG] Context: TABLEI.Objectetectionresults(mAP)ofDiffusionDetmodelpretrainedonCOCO[4]andfine-tunedonDIOR[6]andDOTA[5]datasets\n",
            "incross-domainfew-shotsettings.Wecomparethebaseline(noLoRA),LoRAwithdifferentranks(4,8,32,128),andLoRAappliedafter\n",
            "intermediate fine-tuning. Best results per shot configuration are bold.\n",
            "Baseline LoRA LoRA after a Fine-Tuning\n",
            "Dataset Shots\n",
            "(no LoRA)\n",
            "4 8 32 128 4 8 32 128\n",
            "1 10.66 7.32 6.83 7.51 6.52 11.48 11.58 11.64 11.57\n",
            "5 31.29 24.14 24.84 24.02 24.45 32.40 32.2 32.35 32.45\n",
            "DIOR\n",
            "10 41.50 34.72 34.25 33.91 33.23 40.64 40.68 40.81 41.18\n",
            "50 59.71 56.43 53.41 53.24 56.47 57.72 57.74 57.78 57.70\n",
            "1 4.23 1.86 1.81 1.81 1.70 4.89 4.85 4.84 4.97\n",
            "5 22.52 15.17 14.83 15.15 14.73 22.75 22.83 22.91 22.85\n",
            "DOTA\n",
            "10 32.77 25.12 24.54 25.07 25.06 32.23 32.33 32.30 32.14\n",
            "50 49.17 42.90 42.07 42.50 42.15 47.90 47.99 48.03 47.94\n",
            "V. EXPERIMENTSANDRESULTS runs, we ensure a robust evaluation of LoRAâ€™s effectiveness\n",
            "ToevaluatetheeffectivenessofLoRAincross-domainfew- inmitigatingoverfittingandimprovinggeneralizationincross-\n",
            "shot object detection, we conducted a series of experiments domain few-shot object detection.\n",
            "using the DiffusionDet framework. Our experiments were Across both datasets, the baseline outperforms direct\n",
            "designedtoassesstheimpactofLoRAonmodelperformance, LoRA application in all shot configurations. However, LoRA\n",
            "overfitting, and generalization across domains, particularly in applied after intermediate fine-tuning shows improvements,\n",
            "the challenging context of aerial images. particularly in low-shot settings. On DIOR, the best mAP of\n",
            "We used DiffusionDet model pre-trained on the COCO 11.64 (rank 32) is achieved in the 1-shot setting, while on\n",
            "dataset, using the weights provided by the original authors DOTA,thebestmAPof4.97(rank128)isachieved.Similarly,\n",
            "[10].Forthetargetdomains,weselectedtheDOTAandDIOR in the 5-shot setting, the best mAPs are 32.45 (rank 128) on\n",
            "datasets,whichwereconvertedtoCOCOformat1.Tosimulate DIOR and 22.91 (rank 32) on DOTA. In higher-shot settings,\n",
            "a few-shot setting, we randomly selected k images per class the baseline remains competitive, but LoRA after fine-tuning\n",
            "fortraining,wherekrepresentsthenumberofshots.Toensure closely matches its performance.\n",
            "afaircomparisonandaccountforvariabilityintheselectionof LoRA after intermediate fine-tuning slightly improves\n",
            "images,werepeatedeachexperiment5timesandreportedthe performance in low-shot settings, while the baseline remains\n",
            "average results. Given that DOTA images often contain more strong in higher-shot configurations. The choice of rank in\n",
            "than 100 objects, we set the maximum detection threshold to LoRA has a moderate impact on performance, with lower\n",
            "300 in the pycocoapi evaluation toolkit [25]. ranks(e.g.,4,8)oftenperformingcomparablytohigherranks\n",
            "Allexperimentswereconductedover300epochs,following (e.g., 32, 128).\n",
            "the training protocol established by the original DiffusionDet\n",
            "authors. We evaluated the model performance using the mean VI. DISCUSSION\n",
            "average precision (mAP) at an IoU threshold of 0.5, which is The experimental results demonstrate that LoRA,\n",
            "a standard metric for object detection tasks. For the baseline, particularly when applied after intermediate fine-tuning,\n",
            "we fine-tuned the pre-trained DiffusionDet model on the is a promising approach for cross-domain few-shot object\n",
            "few-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\n",
            "parameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\n",
            "experiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\n",
            "directly to the pre-trained model and applying LoRA to the environments.\n",
            "best checkpoint obtained from the baseline fine-tuning. In the\n",
            "The choice of rank in LoRA has a moderate impact on\n",
            "latter approach, we selected the checkpoint with the highest\n",
            "performance, with lower ranks (e.g., 4, 8) often performing\n",
            "validation performance after 300 epochs and fine-tuned it\n",
            "comparably to higher ranks (e.g., 32, 128). This indicates\n",
            "further using LoRA.\n",
            "\n",
            "few-shot subsets of DOTA and DIOR without freezing any detection. This improvement, although minimal, suggests that\n",
            "parameters. As described in section IV, for the LoRA-based efficient parameter fine-tuning could be a viable alternative\n",
            "experiments, we explored two approaches: applying LoRA to full fine-tuning, particularly in resource-constrained\n",
            "directly to the pre-trained model and applying LoRA to the environments.\n",
            "best checkpoint obtained from the baseline fine-tuning. In the\n",
            "The choice of rank in LoRA has a moderate impact on\n",
            "latter approach, we selected the checkpoint with the highest\n",
            "performance, with lower ranks (e.g., 4, 8) often performing\n",
            "validation performance after 300 epochs and fine-tuned it\n",
            "comparably to higher ranks (e.g., 32, 128). This indicates\n",
            "further using LoRA.\n",
            "that lower ranks may suffice for many applications. However,\n",
            "To investigate the impact of rank selection on LoRAâ€™s\n",
            "thebaselineâ€™sstrongperformanceinhigher-shotconfigurations\n",
            "performance, we tested four different ranks: 4, 8, 32, and\n",
            "underscores the importance of full fine-tuning when sufficient\n",
            "128. The results of these experiments are presented in Tab.\n",
            "data is available. These results underline the need for a\n",
            "I, which compares the performance of the baseline, direct\n",
            "balanced approach, adjusting the fine-tuning strategy to the\n",
            "LoRA application, and LoRA after intermediate fine-tuning\n",
            "specificrequirementsofthetaskanddataset,andcouldbethe\n",
            "across different ranks. By averaging results across multiple\n",
            "subject of further study.\n",
            "While our approach shows promise, it is not without\n",
            "1Theycanbefoundhere:https://huggingface.co/datasets/HichTala/dota,\n",
            "https://huggingface.co/datasets/HichTala/dior. limitations. The performance of LoRA depends on the quality\n",
            "\n",
            "Analyzing the Impact of Low-Rank Adaptation for\n",
            "Cross-Domain Few-Shot Object Detection in Aerial\n",
            "Images\n",
            "Hicham TALAOUBRID Anissa MOKRAOUI Ismail BEN AYED\n",
            "L2TI & COSE L2TI LIVIA, ETS\n",
            "UniversitÃ© Sorbonne Paris Nord UniversitÃ© Sorbonne Paris Nord Montreal, Canada\n",
            "hicham.talaoubrid1@edu.univ-paris13.fr anissa.mokraoui@univ-paris13.fr Ismail.BenAyed@etsmtl.ca\n",
            "Axel PROUVOST Sonimith HANG Monit KORN RÃ©mi HARVEY\n",
            "IMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France IMT Mines AlÃ¨s, France COSE, Montmagny, France\n",
            "axel.prouvost@etu.mines-ales.fr sonimith.hang@etu.mines-ales.fr monit.korn@etu.mines-ales.fr remi.harvey@cose.fr\n",
            "Abstractâ€”This paper investigates the application of Low- domains, the problem becomes even more complex due\n",
            "Rank Adaptation (LoRA) to small models for cross-domain to significant distribution shifts between source and target\n",
            "few-shot object detection in aerial images. Originally designed\n",
            "domains. Traditional fine-tuning approaches often struggle in\n",
            "for large-scale models, LoRA helps mitigate overfitting, making\n",
            "such scenarios as they tend to overfit to the limited training\n",
            "it a promising approach for resource-constrained settings. We\n",
            "integrate LoRA into DiffusionDet, and evaluate its performance data,especiallyinsmallermodelswithfewerparameters.This\n",
            "on the DOTA and DIOR datasets. Our results show that challenge is even greater in cross-domain contexts, where the\n",
            "LoRA applied after an initial fine-tuning slightly improves model needs to generalize to new domains with a minimum\n",
            "performance in low-shot settings (e.g., 1-shot and 5-shot),\n",
            "of supervision.\n",
            "while full fine-tuning remains more effective in higher-shot\n",
            "configurations. These findings highlight LoRAâ€™s potential for\n",
            "efficient adaptation in aerial object detection, encouraging\n",
            "Aerial images present an additional complexity for object\n",
            "further research into parameter-efficient fine-tuning strategies\n",
            "detection. These images often contain numerous small\n",
            "for few-shot learning. Our code is available here: https://github.\n",
            "com/HichTala/LoRA-DiffusionDet objects densely distributed over the scene, as well as\n",
            "Index Termsâ€”Object Detection, Few-Shot Object Detection, significant variations in scale between classes, orientation,\n",
            "Diffusion Models, Cross-Domain, Aerial Images, Low-rank and illumination [3]. These characteristics make aerial images\n",
            "Adaptation. a particularly demanding domain for cross-domain few-shot\n",
            "object-detection.Themainproblemremainsoverfittinginsuch\n",
            "I. INTRODUCTION a scenario. In this work, we investigate the application of\n",
            "LoRA to small models, using the COCO [4] dataset as the\n",
            "The last few years have seen remarkable improvement\n",
            "source domain and the DOTA [5] and DIOR [6] datasets as\n",
            "in large models. Particularly in natural language processing\n",
            "targetdomains.Bothdatasetsarewidelyrecognizedreferences\n",
            "and computer vision [1] [2]. Parameter-efficient fine-tuning\n",
            "for aerial image analysis [7] [8].\n",
            "methodshavebeendevelopedtotraintheseverylargemodels\n",
            "for simpler tasks, without the need to train tens of billions of\n",
            "parameters. One of these is Low Rank Adaptation (LoRA), The motivation behind this work is to address overfitting\n",
            "which, by injecting low rank matrices while freezing the in cross-domain few-shot object detection, particularly for\n",
            "modelâ€™spre-trainingweights,considerablyreducesthenumber aerial images. We explore Low-Rank Adaptation (LoRA)\n",
            "of parameters to be trained in the model. In this way, [9], a technique designed for large models, to improve\n",
            "LoRA helps to limit the overfitting of large models by generalization in smaller architectures like DiffusionDet [10],\n",
            "acceleratingtheirconvergence.Butitspotentialinmodels100 which has about millions of parameters. DiffusionDet has\n",
            "to 1000 times smaller in terms of parameters remains rather shown effectiveness in detecting small objects, making it a\n",
            "unexplored, particularly in a context of cross domain few- goodchoiceforaerialimages.WecompareDiffusionDetwith\n",
            "shot object detection, where the overfitting remains the main and without LoRA, testing two strategies: (1) direct LoRA\n",
            "difficulty. applicationand(2)LoRAafterintermediatefine-tuning.Using\n",
            "Few-shot Object Detection (FSOD) is a challenging theDOTAandDIORdatasets,weevaluatedLoRAâ€™sabilityto\n",
            "task that aims to detect objects from novel categories reduce overfitting and improve generalization, offering insight\n",
            "using only a few labeled examples. When applied across intoitspotentialforefficientandrobustaerialobjectdetection.\n",
            "5202\n",
            "rpA\n",
            "8\n",
            "]VC.sc[\n",
            "1v03360.4052:viXra\n",
            "\n",
            "of the initial fine-tuning. Additionally, our experiments are [7] Z. Chen, H. Wang, X. Wu, J. Wang, X. Lin, C. Wang, K. Gao,\n",
            "limited to DiffusionDet and two aerial datasets; extending M.Chapman,andD.Li,â€œObjectdetectioninaerialimagesusingdota\n",
            "dataset:Asurvey,â€InternationalJournalofAppliedEarthObservation\n",
            "this approach to other architectures and domains could\n",
            "and Geoinformation, vol. 134, p. 104208, 2024. [Online]. Available:\n",
            "yield further insights. Future work could explore combining https://www.sciencedirect.com/science/article/pii/S1569843224005648\n",
            "LoRA with other few-shot learning techniques to enhance its [8] J. Leng, Y. Ye, M. Mo, C. Gao, J. Gan, B. Xiao, and X. Gao,\n",
            "â€œRecentadvancesforaerialobjectdetection:Asurvey,â€ACMComputing\n",
            "effectiveness.\n",
            "Surveys,vol.56,no.12,pp.1â€“36,2024.\n",
            "It is worth noting that the cross-domain scenario explored [9] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang,\n",
            "in this workâ€”adapting from natural images (COCO) to aerial and W. Chen, â€œLora: Low-rank adaptation of large language\n",
            "models,â€ CoRR, vol. abs/2106.09685, 2021. [Online]. Available:\n",
            "images (DOTA and DIOR), remains particularly challenging\n",
            "https://arxiv.org/abs/2106.09685\n",
            "due to the significant differences in perspective, scale, and [10] S. Chen, P. Sun, Y. Song, and P. Luo, â€œDiffusiondet: Diffusion model\n",
            "[11] Y.Wang,R.Zhangetal.,â€œLow-rankadaptationforvisiontransformers\n",
            "would involve adapting between aerial images, such as from\n",
            "DOTAtoDIORorviceversa,wherethedomainshiftsareless [12] L. H. Li, P. Zhang, H. Zhang, J. Yang, C. Li, Y. Zhong,\n",
            "extreme.Onecouldalsoexploreadaptingaerialimagesacross L. Wang, L. Yuan, L. Zhang, J. Hwang, K. Chang, and J. Gao,\n",
            "â€œGrounded language-image pre-training,â€ CoRR, vol. abs/2112.03857,\n",
            "different environments, seasons, or lighting conditions. Such\n",
            "2021.[Online].Available:https://arxiv.org/abs/2112.03857\n",
            "experimentscouldprovidevaluableinsightsintotherobustness [13] M.Kohler,M.Eisenbach,andH.-M.Gross,â€œFew-shotobjectdetection:\n",
            "and versatility of LoRA in less extreme domain shifts. A comprehensive survey,â€ IEEE transactions on neural networks and\n",
            "learningsystems,2021.\n",
            "[14] C. Finn, P. Abbeel, and S. Levine, â€œModel-agnostic meta-learning\n",
            "VII. CONCLUSION for fast adaptation of deep networks,â€ in International Conference on\n",
            "MachineLearning. PMLR,2017,pp.1126â€“1135.\n",
            "In this work, we investigated the application of LoRA [15] W. Xiong, â€œCd-fsod: A benchmark for cross-domain few-shot object\n",
            "to DiffusionDet model for cross-domain few-shot object detection,â€ in ICASSP 2023-2023 IEEE International Conference on\n",
            "Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp.\n",
            "detection, with a focus on the challenging domain of aerial\n",
            "1â€“5.\n",
            "images. Using the DiffusionDet framework, we evaluated the [16] K. Lee, H. Yang, S. Chakraborty, Z. Cai, G. Swaminathan,\n",
            "effectivenessofLoRAinmitigatingoverfittingandimproving A.Ravichandran,andO.Dabeer,â€œRethinkingfew-shotobjectdetection\n",
            "on a multi-domain benchmark,â€ in Computer Visionâ€“ECCV 2022:\n",
            "generalization across the DOTA and DIOR datasets. Our\n",
            "17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022,\n",
            "experiments compared three approaches: (1) baseline fine- Proceedings,PartXX. Springer,2022,pp.366â€“382.\n",
            "tuning, (2) direct LoRA application, and (3) LoRA applied [17] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, â€œAdversarial\n",
            "discriminative domain adaptation,â€ in Proceedings of the IEEE\n",
            "after intermediate fine-tuning. The results demonstrated that\n",
            "conferenceoncomputervisionandpatternrecognition,2017,pp.7167â€“\n",
            "while the baseline outperformed direct LoRA application, 7176.\n",
            "LoRA after intermediate fine-tuning achieved competitive [18] T.-Y.Lin,P.DollÃ¡r,R.Girshick,K.He,B.Hariharan,andS.Belongie,\n",
            "[DEBUG] LLM final answer: content='Low-Rank Adaptation (LoRA) is a parameter-efficient fine-tuning method that involves injecting low-rank matrices into a pre-trained model while freezing the pre-training weights. This technique helps to reduce the number of parameters to be trained, thereby limiting overfitting and accelerating convergence. In the context of this study, LoRA was applied to the DiffusionDet model to evaluate its effectiveness in cross-domain few-shot object detection, particularly for aerial images.\\n\\nThe experiment compared the performance of three approaches:\\n1. Baseline fine-tuning (no LoRA)\\n2. Direct LoRA application\\n3. LoRA applied after intermediate fine-tuning\\n\\nThe results indicated that:\\n- The baseline (no LoRA) generally outperforms direct LoRA application across different shot configurations.\\n- LoRA applied after intermediate fine-tuning shows improvements in low-shot settings, such as 1-shot and 5-shot, where the best mAP values were observed.\\n- In higher-shot configurations, the baseline remains more effective, though LoRA after fine-tuning closely matches its performance.\\n\\nThese findings suggest that LoRA, especially when applied after intermediate fine-tuning, is a promising approach for efficient adaptation in aerial object detection, particularly in scenarios with limited labeled data. However, full fine-tuning remains a stronger option when more labeled data is available.\\n\\nThe choice of rank in LoRA also impacts performance, with lower ranks (e.g., 4, 8) often performing comparably to higher ranks (e.g., 32, 128). This implies that lower ranks may be sufficient for many applications, making LoRA a viable alternative in resource-constrained environments.\\n\\nFor more details, refer to the paper \"Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images\" by Hicham TALAOU BRID et al., pages 5202-5203.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 4162, 'total_tokens': 4557, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-88561442a6bc42a9b2ae6fa35f9007c7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--eec921eb-763d-45dc-a433-feda011df076-0' usage_metadata={'input_tokens': 4162, 'output_tokens': 395, 'total_tokens': 4557, 'input_token_details': {}, 'output_token_details': {}}\n",
            "Chunk: {'generate_answer': {'messages': [AIMessage(content='Low-Rank Adaptation (LoRA) is a parameter-efficient fine-tuning method that involves injecting low-rank matrices into a pre-trained model while freezing the pre-training weights. This technique helps to reduce the number of parameters to be trained, thereby limiting overfitting and accelerating convergence. In the context of this study, LoRA was applied to the DiffusionDet model to evaluate its effectiveness in cross-domain few-shot object detection, particularly for aerial images.\\n\\nThe experiment compared the performance of three approaches:\\n1. Baseline fine-tuning (no LoRA)\\n2. Direct LoRA application\\n3. LoRA applied after intermediate fine-tuning\\n\\nThe results indicated that:\\n- The baseline (no LoRA) generally outperforms direct LoRA application across different shot configurations.\\n- LoRA applied after intermediate fine-tuning shows improvements in low-shot settings, such as 1-shot and 5-shot, where the best mAP values were observed.\\n- In higher-shot configurations, the baseline remains more effective, though LoRA after fine-tuning closely matches its performance.\\n\\nThese findings suggest that LoRA, especially when applied after intermediate fine-tuning, is a promising approach for efficient adaptation in aerial object detection, particularly in scenarios with limited labeled data. However, full fine-tuning remains a stronger option when more labeled data is available.\\n\\nThe choice of rank in LoRA also impacts performance, with lower ranks (e.g., 4, 8) often performing comparably to higher ranks (e.g., 32, 128). This implies that lower ranks may be sufficient for many applications, making LoRA a viable alternative in resource-constrained environments.\\n\\nFor more details, refer to the paper \"Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images\" by Hicham TALAOU BRID et al., pages 5202-5203.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 4162, 'total_tokens': 4557, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-88561442a6bc42a9b2ae6fa35f9007c7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--eec921eb-763d-45dc-a433-feda011df076-0', usage_metadata={'input_tokens': 4162, 'output_tokens': 395, 'total_tokens': 4557, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
            "Node: generate_answer, Update: {'messages': [AIMessage(content='Low-Rank Adaptation (LoRA) is a parameter-efficient fine-tuning method that involves injecting low-rank matrices into a pre-trained model while freezing the pre-training weights. This technique helps to reduce the number of parameters to be trained, thereby limiting overfitting and accelerating convergence. In the context of this study, LoRA was applied to the DiffusionDet model to evaluate its effectiveness in cross-domain few-shot object detection, particularly for aerial images.\\n\\nThe experiment compared the performance of three approaches:\\n1. Baseline fine-tuning (no LoRA)\\n2. Direct LoRA application\\n3. LoRA applied after intermediate fine-tuning\\n\\nThe results indicated that:\\n- The baseline (no LoRA) generally outperforms direct LoRA application across different shot configurations.\\n- LoRA applied after intermediate fine-tuning shows improvements in low-shot settings, such as 1-shot and 5-shot, where the best mAP values were observed.\\n- In higher-shot configurations, the baseline remains more effective, though LoRA after fine-tuning closely matches its performance.\\n\\nThese findings suggest that LoRA, especially when applied after intermediate fine-tuning, is a promising approach for efficient adaptation in aerial object detection, particularly in scenarios with limited labeled data. However, full fine-tuning remains a stronger option when more labeled data is available.\\n\\nThe choice of rank in LoRA also impacts performance, with lower ranks (e.g., 4, 8) often performing comparably to higher ranks (e.g., 32, 128). This implies that lower ranks may be sufficient for many applications, making LoRA a viable alternative in resource-constrained environments.\\n\\nFor more details, refer to the paper \"Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images\" by Hicham TALAOU BRID et al., pages 5202-5203.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 4162, 'total_tokens': 4557, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': None, 'id': 'chatcmpl-88561442a6bc42a9b2ae6fa35f9007c7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--eec921eb-763d-45dc-a433-feda011df076-0', usage_metadata={'input_tokens': 4162, 'output_tokens': 395, 'total_tokens': 4557, 'input_token_details': {}, 'output_token_details': {}})]}\n"
          ]
        }
      ],
      "source": [
        "def gradio_agentic_rag(pdf_file, question, history=None):\n",
        "    pdf_bytes, filename = get_file_bytes_and_name(pdf_file)\n",
        "    vectordb = load_or_create_chroma(pdf_bytes, filename)\n",
        "    # retriever_tool = build_retriever_tool(vectordb)\n",
        "    retriever_tool = build_retriever_tool(vectordb)\n",
        "    graph = build_agentic_graph(retriever_tool)\n",
        "    state_messages = []\n",
        "    if history:\n",
        "        for turn in history:\n",
        "            if isinstance(turn, list) or isinstance(turn, tuple):\n",
        "                if turn[0]:\n",
        "                    state_messages.append({\"role\": \"user\", \"content\": turn[0]})\n",
        "                if len(turn) > 1 and turn[1]:\n",
        "                    state_messages.append({\"role\": \"assistant\", \"content\": turn[1]})\n",
        "    # Add the current question\n",
        "    state_messages.append({\"role\": \"user\", \"content\": question})\n",
        "    state = {\"messages\": state_messages}\n",
        "\n",
        "    # Run through the agentic graph workflow (streaming or just final)\n",
        "    result = None\n",
        "    for chunk in graph.stream(state):\n",
        "        print(f\"Chunk: {chunk}\")\n",
        "        for node, update in chunk.items():\n",
        "            print(f\"Node: {node}, Update: {update}\")\n",
        "            # If the LLM answered directly and did NOT trigger the tool\n",
        "            last_msg = update[\"messages\"][-1]\n",
        "            if node == \"generate_answer\" or (\n",
        "                node == \"generate_query_or_respond\" and not update[\"messages\"][-1].tool_calls\n",
        "            ):\n",
        "                result = last_msg.content\n",
        "        # Fallback (if for some reason nothing returned)\n",
        "    # if result is None:\n",
        "    #     result = \"No answer generated.\"\n",
        "    if history is None:\n",
        "        history = []\n",
        "    history.append([question, result])\n",
        "\n",
        "    return result, history\n",
        "    # return result or \"No answer generated.\"\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_agentic_rag,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload your PDF\"),\n",
        "        gr.Textbox(label=\"Ask a question about your PDF\"),\n",
        "        gr.State()\n",
        "    ],\n",
        "    outputs=[gr.Textbox(label=\"Answer from RAG Agent\"),\n",
        "              gr.State()],\n",
        "    title=\"Agentic RAG PDF Q&A\",\n",
        "    description=\"Upload a PDF and ask any question about its contents. The AI will read and answer using only the information from your file.\"\n",
        "\n",
        ")\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(\n",
        "        mcp_server=True,\n",
        "        show_error=True,\n",
        "        show_api=True\n",
        "        )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mcp_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "025851cd236c41129503c1ddacf62c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063e6591e62942e6a891ee4fd0fc4f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09d5958ede814008bac85304b9e8c768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3d226db0ae42dbb1f9f0ebbc8db52e",
            "max": 2271064456,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43a9be75c016488b84c49b680b129b34",
            "value": 2271064456
          }
        },
        "0d0b61c1203b45569076708adba47b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6e4273dcfc40f8b24fd84bee1a715c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "103ded8f22c84a8dbbdbc10d533c324a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1310648fb9f240d2a5ebd71e3e4ac352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef5f0ecb42ab4558830a7fb11b70b1a5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d22ab5f995b6467f93caa6f419a96167",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "131620843a094e248361d1bc4896b2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142398f32e3a4bffaf3f65020b09d99f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1693f813de7c48ebac0a8adbcd74fd51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b7b079d6a6a4c4f96e6c95ddb5a3ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b96592199b14a0d97eaf492874ca20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c70b30501134312a980cd35d90dd674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1310648fb9f240d2a5ebd71e3e4ac352",
              "IPY_MODEL_6f16995cfe9044b1ba7f87623aaeb784",
              "IPY_MODEL_c78b49ebe9a3421086983c6172e0913d"
            ],
            "layout": "IPY_MODEL_497c9728938b4aa5a01d8eac5457b191"
          }
        },
        "1d36e496890c404e92101ac453d12f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e87b5199fbe42ddbf17784edb27e10e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec9a47f99c04a2ca2172f0c47b0c3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12e3176d41c4fcda3b13a6cd983a157",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e7f6fc7e3f9f48fdbc432d5c86ee0a74",
            "value": "sentencepiece.bpe.model:â€‡100%"
          }
        },
        "22499d3939b545938d65a5909f02766d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a83708bb0b4a2086c92a95e6624021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2417110ee2124366ac8708fda2a7b904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "286c9d6cdcf4420a8f868d65ea173c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41a431d09f8437e9bdc8753178cc089",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_025851cd236c41129503c1ddacf62c8c",
            "value": "â€‡191/191â€‡[00:00&lt;00:00,â€‡6.94kB/s]"
          }
        },
        "2a2a39ae5323447fa70a18da0175eec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7502dcacd7412e98d1a5cf263e248e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_816f1e68e2314e72a2074176117f3f3e",
            "value": "config.json:â€‡100%"
          }
        },
        "2d78949de0c345caaa80aa780e0934f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3129845c57ff420ea08afc18e759ff03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2d9a486801641128790693f6b811341",
              "IPY_MODEL_897c2c43a4b643fd8089904e2be2be76",
              "IPY_MODEL_a9fa96245b3244ac947f228aa962a53c"
            ],
            "layout": "IPY_MODEL_7a46fe31b6454df08236a3e007760d28"
          }
        },
        "32a3547cacdb4d15804899b8970ad58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44a89aafd86946bf92db65bcf1b5931e",
              "IPY_MODEL_09d5958ede814008bac85304b9e8c768",
              "IPY_MODEL_a1f41c8e7fbb4aeb8855c52cc478ea99"
            ],
            "layout": "IPY_MODEL_a2e2321c58d3463bb7c5ffba67f6bf34"
          }
        },
        "32d1e8f4521b49aab78342448efaa338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c337c93dae4075a792069576df99f5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_49d94e86656140efa2167a2b40cccd73",
            "value": "â€‡444/444â€‡[00:00&lt;00:00,â€‡15.2kB/s]"
          }
        },
        "38d8f33510ef47d894eebcbeee08d437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e87b5199fbe42ddbf17784edb27e10e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d9dd995cca374fd580e0b8dfd0cc1013",
            "value": "config_sentence_transformers.json:â€‡100%"
          }
        },
        "3e651b07d24743e7879935a2e1459d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5253662f034283b08189c37082f038",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_affbf9b569fb4d639db71b59ee110971",
            "value": "README.md:â€‡100%"
          }
        },
        "40aae9a337f145538a8c5ac1b97d3312": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4337f57e09374dd9b8cbf81ce7fda17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fea39e25d24b02aea5fb4cdb56d4fa",
            "max": 687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2c5c2dabab64ed68f6dda058729ba88",
            "value": 687
          }
        },
        "43a9be75c016488b84c49b680b129b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44a89aafd86946bf92db65bcf1b5931e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32d457f0f8e45c189684d7ec8bee5da",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_59250aa1f5d44ce6902c40317510a71f",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "46188d48a66147b683871b43402c0fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f33e1bc6ad447ea294a1af4a41a9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47c337c93dae4075a792069576df99f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497c9728938b4aa5a01d8eac5457b191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c5def60dc24f97afca4c5f1032c29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49d94e86656140efa2167a2b40cccd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a9fa1a2b7d94d95963ae208ce36cc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46188d48a66147b683871b43402c0fe5",
            "max": 191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73a097cb74254b9cb2330a74d8ec23fe",
            "value": 191
          }
        },
        "4ed4b4d8ce244f6ca4e03b86920983b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb6d0e2a71f4a29a248fd6c2227cc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ec9a47f99c04a2ca2172f0c47b0c3f0",
              "IPY_MODEL_dadd04eea7ee420b9a6dad87c464c232",
              "IPY_MODEL_88256ec2f1f74fdfa02b230b45b6f2b8"
            ],
            "layout": "IPY_MODEL_ce22a7a57cc045d6ac05baa7e433fb42"
          }
        },
        "522f568c33264fb2a825c5b5a0440681": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a9f2c47b904f89abba682034e5e7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0b61c1203b45569076708adba47b2d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fba5aa0ff3d14cc1b7c750cbe387db7d",
            "value": "sentence_bert_config.json:â€‡100%"
          }
        },
        "53efb6f2caf74690995eca392a283a63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559dede944534990aad82cfe109f50ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57486e1bee634103aa480427f0b6ec08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40aae9a337f145538a8c5ac1b97d3312",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f6e4273dcfc40f8b24fd84bee1a715c",
            "value": 349
          }
        },
        "59250aa1f5d44ce6902c40317510a71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c613320f9e742a2b92895c10495b301": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e651b07d24743e7879935a2e1459d5e",
              "IPY_MODEL_bdd5d4554d3b4453b6bfe3baa0d9d855",
              "IPY_MODEL_7d1e3e77c4fd491888855a001d893193"
            ],
            "layout": "IPY_MODEL_b70cac465c114f999e0107ef94090e02"
          }
        },
        "5c7502dcacd7412e98d1a5cf263e248e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df6bcfae5a34f57b1e0652632ec7975": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38d8f33510ef47d894eebcbeee08d437",
              "IPY_MODEL_faf5e9d426fd468cb7ff98ebc1150e05",
              "IPY_MODEL_874c09f5a4b14ee197f447ede88c3a01"
            ],
            "layout": "IPY_MODEL_9aeff405f7e143868972a21fe77df5c1"
          }
        },
        "68a3274bfd0e40f9b9468b94f774c65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53a9f2c47b904f89abba682034e5e7d2",
              "IPY_MODEL_942bafa6818f4cb9aba20912b6dc1c3f",
              "IPY_MODEL_7fa73d2ebd3544ad84d405912aa8c59a"
            ],
            "layout": "IPY_MODEL_89c7431bf9db4e678fccd4cc73cac10e"
          }
        },
        "699a76c40cf9434ea2dfb2880f73a9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69e995a99f1f420a9d26e8421fdb1b48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb0b63f3e3b4decbf8b82aec9926be8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f16995cfe9044b1ba7f87623aaeb784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e995a99f1f420a9d26e8421fdb1b48",
            "max": 17098108,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a21917da551a48f389c4f27f756c202b",
            "value": 17098108
          }
        },
        "6f27d902c38b48cb8248f95adaccf594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53efb6f2caf74690995eca392a283a63",
            "max": 444,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b7b079d6a6a4c4f96e6c95ddb5a3ee7",
            "value": 444
          }
        },
        "6f3d226db0ae42dbb1f9f0ebbc8db52e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fb894aad404373ba8c093667af2b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa39cd16d754a75956e63145b42e5be",
            "max": 964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d36e496890c404e92101ac453d12f35",
            "value": 964
          }
        },
        "73a097cb74254b9cb2330a74d8ec23fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "795adb5e52174b468ba0f4dbe5a32539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "796dc6e4540a41a882e47e139e998d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a46fe31b6454df08236a3e007760d28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1e3e77c4fd491888855a001d893193": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83cd097a36bc4cc38f3a430f5afd513b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_22499d3939b545938d65a5909f02766d",
            "value": "â€‡15.8k/15.8kâ€‡[00:00&lt;00:00,â€‡444kB/s]"
          }
        },
        "7fa73d2ebd3544ad84d405912aa8c59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6918205ee445e7adcfdb57decf87d5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_931137748edc44749f4e32fb92009f8f",
            "value": "â€‡54.0/54.0â€‡[00:00&lt;00:00,â€‡2.11kB/s]"
          }
        },
        "80d1beac3e2d435081981c8bf599e3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "816f1e68e2314e72a2074176117f3f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83cd097a36bc4cc38f3a430f5afd513b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e3343126aa489284e2ccfbd6dd0ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874c09f5a4b14ee197f447ede88c3a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131620843a094e248361d1bc4896b2d0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_063e6591e62942e6a891ee4fd0fc4f4a",
            "value": "â€‡123/123â€‡[00:00&lt;00:00,â€‡3.70kB/s]"
          }
        },
        "88256ec2f1f74fdfa02b230b45b6f2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522f568c33264fb2a825c5b5a0440681",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2417110ee2124366ac8708fda2a7b904",
            "value": "â€‡5.07M/5.07Mâ€‡[00:00&lt;00:00,â€‡19.8MB/s]"
          }
        },
        "897c2c43a4b643fd8089904e2be2be76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103ded8f22c84a8dbbdbc10d533c324a",
            "max": 2271145830,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1d5797dee743149324a86312453313",
            "value": 2271145830
          }
        },
        "89c7431bf9db4e678fccd4cc73cac10e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d5d0a351b764af69b350f385f9b8a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcfdac76aa4b4f81a2919120000ca5fc",
              "IPY_MODEL_70fb894aad404373ba8c093667af2b99",
              "IPY_MODEL_ac12a34d49ef41fd8102111a3ab013b3"
            ],
            "layout": "IPY_MODEL_e0877c08a87a46c1b088f02189b46e85"
          }
        },
        "931137748edc44749f4e32fb92009f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "942bafa6818f4cb9aba20912b6dc1c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f999c2cbd3f848e1992caac791b93f31",
            "max": 54,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46f33e1bc6ad447ea294a1af4a41a9af",
            "value": 54
          }
        },
        "950cb5b687e24000863dc5aa11e9eafc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982650b100534a24828cd2b6c2f22930": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29b7bccb7d645c5968bfce8eb1f5652",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c24968ac006847cabcd295f518dc9482",
            "value": "modules.json:â€‡100%"
          }
        },
        "9a3b1117e200404fbf618b7574cb9774": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aeff405f7e143868972a21fe77df5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1d5797dee743149324a86312453313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ffec56b78d04badabd0e2f02dade714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d78949de0c345caaa80aa780e0934f2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d9e3227c1db74df29bf6121b2aeb524f",
            "value": "â€‡687/687â€‡[00:00&lt;00:00,â€‡19.5kB/s]"
          }
        },
        "a072a5af013c4e35a928b520e800ceff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12e3176d41c4fcda3b13a6cd983a157": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f41c8e7fbb4aeb8855c52cc478ea99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e90a6b57574e83ac4224d5938b6dc2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dfb5ee6d01bd4d5bac7a56f01ec069f3",
            "value": "â€‡2.27G/2.27Gâ€‡[00:19&lt;00:00,â€‡264MB/s]"
          }
        },
        "a21917da551a48f389c4f27f756c202b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2659e102400400586d017104043047f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed4b4d8ce244f6ca4e03b86920983b6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_80d1beac3e2d435081981c8bf599e3bc",
            "value": "â€‡349/349â€‡[00:00&lt;00:00,â€‡10.8kB/s]"
          }
        },
        "a2e2321c58d3463bb7c5ffba67f6bf34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a517ea27204f469eab09e90cacc0e757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3b1117e200404fbf618b7574cb9774",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c2b62d1556b042758f5f319ed0bb1ff0",
            "value": "config.json:â€‡100%"
          }
        },
        "a53b9608a5e746d0bc80b35d273536dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d64b90eadb4a619fa01aec3ddf02c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9fa96245b3244ac947f228aa962a53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e3343126aa489284e2ccfbd6dd0ab4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a072a5af013c4e35a928b520e800ceff",
            "value": "â€‡2.27G/2.27Gâ€‡[00:13&lt;00:00,â€‡235MB/s]"
          }
        },
        "ac12a34d49ef41fd8102111a3ab013b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a83708bb0b4a2086c92a95e6624021",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eca04492027e4421808c388311842900",
            "value": "â€‡964/964â€‡[00:00&lt;00:00,â€‡31.1kB/s]"
          }
        },
        "ae6918205ee445e7adcfdb57decf87d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affbf9b569fb4d639db71b59ee110971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2c5c2dabab64ed68f6dda058729ba88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2d9a486801641128790693f6b811341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950cb5b687e24000863dc5aa11e9eafc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a9d64b90eadb4a619fa01aec3ddf02c2",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "b2e90a6b57574e83ac4224d5938b6dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d5316bca1b47ffbfbbf4b81f97677d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_982650b100534a24828cd2b6c2f22930",
              "IPY_MODEL_57486e1bee634103aa480427f0b6ec08",
              "IPY_MODEL_a2659e102400400586d017104043047f"
            ],
            "layout": "IPY_MODEL_f26bf85d31024f9ba8a24b4b0061dabf"
          }
        },
        "b70cac465c114f999e0107ef94090e02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdd5d4554d3b4453b6bfe3baa0d9d855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d749edb8f8e9424da6dba63f2f549ba5",
            "max": 15822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_796dc6e4540a41a882e47e139e998d97",
            "value": 15822
          }
        },
        "c24968ac006847cabcd295f518dc9482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b62d1556b042758f5f319ed0bb1ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c475c20e06b04a318ed77a042570af95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78b49ebe9a3421086983c6172e0913d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1693f813de7c48ebac0a8adbcd74fd51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c475c20e06b04a318ed77a042570af95",
            "value": "â€‡17.1M/17.1Mâ€‡[00:03&lt;00:00,â€‡5.22MB/s]"
          }
        },
        "cdf572db970e4b98ae01c504f2a94803": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53b9608a5e746d0bc80b35d273536dd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1b96592199b14a0d97eaf492874ca20e",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "ce22a7a57cc045d6ac05baa7e433fb42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbc4171d3104a71bc5d08cf003ed58f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22ab5f995b6467f93caa6f419a96167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2fea39e25d24b02aea5fb4cdb56d4fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41a431d09f8437e9bdc8753178cc089": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d749edb8f8e9424da6dba63f2f549ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ae7d550e02405e922b18854819c424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a517ea27204f469eab09e90cacc0e757",
              "IPY_MODEL_4337f57e09374dd9b8cbf81ce7fda17d",
              "IPY_MODEL_9ffec56b78d04badabd0e2f02dade714"
            ],
            "layout": "IPY_MODEL_cfbc4171d3104a71bc5d08cf003ed58f"
          }
        },
        "d9dd995cca374fd580e0b8dfd0cc1013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e3227c1db74df29bf6121b2aeb524f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dadd04eea7ee420b9a6dad87c464c232": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142398f32e3a4bffaf3f65020b09d99f",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_795adb5e52174b468ba0f4dbe5a32539",
            "value": 5069051
          }
        },
        "db07f4f9259547a8826d8f6d23a983df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a2a39ae5323447fa70a18da0175eec0",
              "IPY_MODEL_4a9fa1a2b7d94d95963ae208ce36cc27",
              "IPY_MODEL_286c9d6cdcf4420a8f868d65ea173c40"
            ],
            "layout": "IPY_MODEL_fb827250c250438a807fda758ba0ee12"
          }
        },
        "ddb77d6eabd14526888186556c4079cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa39cd16d754a75956e63145b42e5be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb5ee6d01bd4d5bac7a56f01ec069f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0877c08a87a46c1b088f02189b46e85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f6fc7e3f9f48fdbc432d5c86ee0a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec5253662f034283b08189c37082f038": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca04492027e4421808c388311842900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef5f0ecb42ab4558830a7fb11b70b1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26bf85d31024f9ba8a24b4b0061dabf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29b7bccb7d645c5968bfce8eb1f5652": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32d457f0f8e45c189684d7ec8bee5da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f999c2cbd3f848e1992caac791b93f31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf5e9d426fd468cb7ff98ebc1150e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb77d6eabd14526888186556c4079cb",
            "max": 123,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49c5def60dc24f97afca4c5f1032c29a",
            "value": 123
          }
        },
        "fb827250c250438a807fda758ba0ee12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba5aa0ff3d14cc1b7c750cbe387db7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcee393ca8344a0fb25f293dd3d90bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdf572db970e4b98ae01c504f2a94803",
              "IPY_MODEL_6f27d902c38b48cb8248f95adaccf594",
              "IPY_MODEL_32d1e8f4521b49aab78342448efaa338"
            ],
            "layout": "IPY_MODEL_6bb0b63f3e3b4decbf8b82aec9926be8"
          }
        },
        "fcfdac76aa4b4f81a2919120000ca5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559dede944534990aad82cfe109f50ef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_699a76c40cf9434ea2dfb2880f73a9a1",
            "value": "special_tokens_map.json:â€‡100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
